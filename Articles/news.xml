<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Ars Technica</title>
	<atom:link href="https://arstechnica.com/feed/?t=c951724f17882c293435a61d10002d8b" rel="self" type="application/rss+xml" />
	<link>https://arstechnica.com</link>
	<description>Serving the Technologist for more than a decade. IT news, reviews, and analysis.</description>
	<lastBuildDate>Mon, 18 Nov 2019 15:11:07 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.8.11</generator>

<image>
	<url>https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-32x32.png</url>
	<title>Ars Technica</title>
	<link>https://arstechnica.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Google expands today’s Stadia’s launch lineup to 22 games [Updated]</title>
		<link>https://arstechnica.com/?p=1600451</link>
		<pubDate>Mon, 18 Nov 2019 14:52:56 +0000</pubDate>
		<dc:creator><![CDATA[Kyle Orland]]></dc:creator>
				<category><![CDATA[Gaming & Culture]]></category>
		<category><![CDATA[google]]></category>
		<category><![CDATA[stadia]]></category>
		<category><![CDATA[streaming]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1600451</guid>
		<description><![CDATA[A few more by year's end; some previously promised "launch" titles are not here yet.]]></description>
				<content:encoded><![CDATA[





<div><a name='page-1'></a></div>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/06/P6_FE_R03-980x572.png" alt=""></div>
        <p>
          The hardware you get with the $129.99 Stadia "Founder's Edition."                      [credit:
                        <a href="https://about.google/">Google</a>
                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<p>[<strong>Update (Nov. 18): </strong>Late Sunday night, Google announced that ten games that were originally planned for a post-launch 2020 release will actually be available on Stadia later today. They are:</p>
<ul>
<li><em>Attack on Titan 2: Final Battle</em></li>
<li><em>Farming Simulator 19</em></li>
<li><em><a href="https://arstechnica.com/tag/final-fantasy-xv/">Final Fantasy XV</a></em></li>
<li><em>Football Manager 2020</em></li>
<li><em>Grid (2019)</em></li>
<li><em><a href="https://arstechnica.com/gaming/2019/02/metro-exodus-a-good-single-player-game-to-usher-in-the-pc-ray-tracing-era/">Metro Exodus</a></em></li>
<li><em>NBA 2K20</em></li>
<li><em><a href="https://arstechnica.com/gaming/2018/06/rage-2-at-e3-dooms-punk-rock-sibling-feels-great-to-play/">Rage 2</a></em></li>
<li><em>Trials Rising</em></li>
<li><em><a href="https://arstechnica.com/gaming/2019/07/wolfenstein-youngblood-review-in-my-day-we-called-this-an-expansion-pack/">Wolfenstein: Youngblood</a></em></li>
</ul>
<p>This brings the Stadia launch day lineup up to 22 titles. <em>Borderlands 3</em>, <em>Ghost Recon: Breakpoint</em>, <em>Dragon Ball: Xenoverse</em> and <em>Darksiders Genesis </em>are still planned for Stadia release sometime this year. In addition, Ubisoft's <em>Watch Dogs: Legion</em> and <em>Gods &amp; Monsters </em>are planned to launch on Stadia in 2020.</p>
<p>Google also announced that fighting game <em>Samurai Shodown</em> will be included as part of November's Stadia Pro subscriber freebies.]</p>
<p><strong>Original story</strong></p>
<p>Today, Google announced 12 games that will be available for <a href="https://arstechnica.com/gaming/2019/06/despite-revolutionary-promises-stadias-biz-model-is-pure-establishment/">individual purchase</a> and streaming when <a href="https://arstechnica.com/gaming/2019/10/google-cant-fulfill-all-stadia-pre-orders-for-nov-19-launch/">Founders Edition pre-orderers</a> get their hands on Google Stadia<a href="https://arstechnica.com/gaming/2019/10/google-stadia-launching-at-9-a-m-pst-november-19/"> starting November 19</a>. The games are:</p>
<ul>
<li><em><a href="https://arstechnica.com/gaming/2018/10/assassins-creed-odyssey-review-epic-scale-forgettable-choices/">Assassin's Creed Odyssey</a></em></li>
<li><em><a href="https://arstechnica.com/gaming/2018/09/destiny-2-forsaken-review-hallelujah-destinys-back/">Destiny 2</a>: The Collection (included with Stadia Pro subscription)</em></li>
<li><em>Gylt</em></li>
<li><em>Just Dance 2020</em></li>
<li><em>Kine</em></li>
<li><em><a href="https://arstechnica.com/gaming/2019/05/mortal-kombat-11-review-great-gameplay-excessively-packaged/">Mortal Kombat 11</a></em></li>
<li><em><a href="https://arstechnica.com/gaming/2018/10/red-dead-redemption-ii-review-getting-muddy-in-the-wide-open-frontier/">Red Dead Redemption 2</a></em></li>
<li><em><a href="https://arstechnica.com/gaming/2015/11/rise-of-the-tomb-raider-review-this-is-laras-best-adventure-yet/">Rise of the Tomb Raider</a></em></li>
<li><em>Samurai Shodown</em> (included with Stadia Pro subscription)</li>
<li><em><a href="https://arstechnica.com/gaming/2018/09/shadow-of-the-tomb-raider-review-fighting-for-my-life-and-loving-it/">Shadow of the Tomb Raider</a>: Definitive Edition</em></li>
<li><em><a href="https://arstechnica.com/gaming/2016/12/ars-technicas-best-video-games-of-2016/">Thumper</a></em></li>
<li><em>Tomb Raider: Definitive Edition</em></li>
<li>[See update above for late additions to this list]</li>
</ul>
<p>Fourteen additional titles are promised to launch on Stadia before the end of 2019:</p>
<ul>
<li><em>Attack on Titan 2: Final Battle*</em></li>
<li><em><a href="https://arstechnica.com/gaming/2019/09/so-far-borderlands-3-is-equal-parts-entrancing-and-annoying/">Borderlands 3</a>*</em></li>
<li><em>Darksiders: Genesis*</em></li>
<li><em>Dragonball Xenoverse 2</em></li>
<li><em>Farming Simulator 19*</em></li>
<li><em><a href="https://arstechnica.com/tag/final-fantasy-xv/">Final Fantasy XV</a>*</em></li>
<li><em>Football Manager 2020*</em></li>
<li><em>Ghost Recon: Breakpoint</em></li>
<li><em>Grid (2019)*</em></li>
<li><em><a href="https://arstechnica.com/gaming/2019/02/metro-exodus-a-good-single-player-game-to-usher-in-the-pc-ray-tracing-era/">Metro Exodus</a>*</em></li>
<li><em>NBA 2K20*</em></li>
<li><em><a href="https://arstechnica.com/gaming/2018/06/rage-2-at-e3-dooms-punk-rock-sibling-feels-great-to-play/">Rage 2</a>*</em></li>
<li><em>Trials Rising*</em></li>
<li><em><a href="https://arstechnica.com/gaming/2019/07/wolfenstein-youngblood-review-in-my-day-we-called-this-an-expansion-pack/">Wolfenstein: Youngblood</a>*</em></li>
<li>[* - added to launch lineup Sunday night]</li>
</ul>
<p>A number of legacy titles that were previously promised as part of the Stadia "launch window" are currently not included in Google's list of 2019 Stadia releases. Those include:</p>
<ul>
<li><em><a href="https://arstechnica.com/gaming/2018/07/the-crew-2-review-where-is-everybody/">The Crew 2</a></em></li>
<li><em>Destroy All Humans</em></li>
<li><em><a href="https://arstechnica.com/gaming/2016/05/doom-2016-single-player-review-back-to-basics/">Doom</a></em> (2016)</li>
<li><em><a href="https://arstechnica.com/tag/elder-scrolls/">The Elder Scrolls</a> Online</em></li>
<li><em>Power Rangers: Battle for the Grid</em></li>
<li><em><a href="https://arstechnica.com/gaming/2016/02/superhot-review-time-is-on-my-side/">Superhot</a></em></li>
<li><em>Windjammers 2</em></li>
</ul>
<p>Major publishers Capcom and EA are also absent from Stadia's current planned 2019 lineup, though both were listed as participating in Stadia's "launch window" as recently as August. Google has not yet responded to a request for comment on those omissions. [Update: A Google spokesperson told Ars that "'launch window' conveyed the first few months after launch.  What we announced today was the first 6 weeks."]</p>
<p>A handful of other unreleased titles that were promised for the Stadia launch window have simply been delayed into 2020. Those include:</p>
<ul>
<li><em>Baldur's Gate 3</em></li>
<li><em><a href="https://arstechnica.com/gaming/2018/08/cyberpunk-2077s-hour-long-gun-filled-e3-gameplay-reveal-has-gone-live/">Cyberpunk 2077</a></em></li>
<li><em><a href="https://arstechnica.com/gaming/2018/08/doom-eternal-reveals-new-powers-puts-hell-back-on-earth/">Doom Eternal</a></em></li>
<li><em>Get Packed</em> (Stadia exclusive)</li>
<li><em>Orcs Must Die 3</em> (timed Stadia exclusive)</li>
</ul>
<p>Of the 26 titles planned for Stadia release this year, <a href="https://arstechnica.com/gaming/2019/08/get-ready-to-jump-in-the-stream-for-google-stadias-exclusive-games/">Tequila Works' horror game <em>Gylt</em></a> is the only one that won't be available on other platforms concurrently (though Google has <a href="https://arstechnica.com/gaming/2019/10/google-wants-stadia-exclusives-that-are-not-possible-on-any-other-platform/">an internal development studio working on more exclusives</a> in the coming months and years). <em>Darksiders: Genesis</em> is due to launch simultaneously on PC and Stadia on December 5.</p>
<p>Looking at the 24 remaining 2019 Stadia games, 15 were first released on other platforms sometime in 2019, and five more were first released in 2018. The list of 2018 releases includes <em>Farming Simulator 19</em>, even though an updated "2020" version of the franchise is due for release on other platforms December 3. And while <em>Football Manager 2020</em> will also be launching on other platforms November 19, developer Sports Interactive <a href="https://arstechnica.com/gaming/2019/08/developer-says-stadia-will-have-the-fastest-version-of-football-manager/">has said</a> the Stadia version will offer "the fastest way to experience <em>Football Manager" </em>thanks to Google's cloud data centers.</p>
<p>At launch, Stadia is only available <a href="https://arstechnica.com/gaming/2019/06/google-stadia-requires-130-upfront-10-per-month-at-november-launch/">via the purchase of a $130 bundle</a> that includes a Stadia controller and a Chromecast Ultra for TV play. A free tier, which does not require a separate hardware purchase or a $10/month "Stadia Pro" subscription, is planned for next year.</p>
<div class="video"><div class="wrapper"<iframe style="display:block" type="text/html" width="640" height="360" src="https://www.youtube.com/embed/Pwb6d2wK3Qw?start=0&wmode=transparent" frameborder="0" allowfullscreen></iframe></div></div>

<p><a href="https://arstechnica.com/?p=1600451&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>China now launches more rockets than anyone in the world</title>
		<link>https://arstechnica.com/?p=1603251</link>
		<pubDate>Mon, 18 Nov 2019 14:28:43 +0000</pubDate>
		<dc:creator><![CDATA[Eric Berger]]></dc:creator>
				<category><![CDATA[Science]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1603251</guid>
		<description><![CDATA[Through Sunday, the country has launched 27 orbital missions this year.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-1180050227-800x534.jpg" alt="The 49th Beidou navigation satellite was successfully launched by a Long March 3b carrier rocket from the Xichang Satellite Launch Center in southwest China on November 5, 2019."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-1180050227.jpg" class="enlarge-link" data-height="683" data-width="1024">Enlarge</a> <span class="sep">/</span> The 49th Beidou navigation satellite was successfully launched by a Long March 3b carrier rocket from the Xichang Satellite Launch Center in southwest China on November 5, 2019. (credit:  Costfoto / Barcroft Media via Getty Images)</p>  </figure>






<div><a name='page-1'></a></div>
<p>In recent weeks, China's space program has made news by revealing some of its long-term ambitions for spaceflight. These include establishing an Earth-Moon space economic zone by 2050, which, if successful, <a href="https://www.thespacereview.com/article/3828/1">could allow</a> the country to begin to dictate the rules of behavior for future space exploration.</p>
<p>Some have questioned whether China, which has flown six human spaceflights in the last 16 years, can really build a large low-Earth space station, send taikonauts to the Moon, return samples from Mars, and more in the coming decade or two. But what seems clear is that the country's authoritarian government has long-term plans and is taking steps toward becoming a global leader in space exploration.</p>
<p>By one important metric—orbital launches—China has already reached this goal.</p>
<p>In 2018, the country <a href="https://gbtimes.com/china-to-attempt-more-than-40-space-launches-in-2018-including-long-march-5-and-lunar-far-side-missions">set a goal</a> of 35 orbital launches and ended up with 39 launch attempts. That year, the United States (29 flights) and Russia (20) trailed China, according to <a href="http://www.spacelaunchreport.com/log2018.html">Space Launch Report</a>. It marked the first time China led the world in the number of successful orbital launches.</p>

<p>This year, China is set to pace the world again. Through Sunday, the country has launched 27 orbital missions, followed by Russia (19), and the United States (16). Although nearly a month and a half remain in this year, a maximum of six additional orbital launches are likely from the United States in 2019.</p>
<p>To be fair, China's space launch program has not been without hiccups. The country's space program is still trying to bring its <a href="https://arstechnica.com/science/2016/11/china-now-has-a-rocket-that-can-land-taikonauts-on-the-moon/">large Long March 5 vehicle</a> back into service after a catastrophic failure during just its second mission, in July 2017. And the country had three failures in 2018 and 2019, compared to just one in the United States and Russia combined.</p>
<h2>US launches down</h2>
<p>The United States has taken a step back this year in part due to decreased activity by SpaceX. The company launched a record 21 missions last year but has so far launched 11 rockets in 2019. A flurry of missions remains possible in the next six weeks for the company, including a space station resupply mission in early December, a commercial satellite launch, and additional Starlink flights.</p>
<p>Another big factor has been a slow year for United Launch Alliance. The Colorado-based company has launched just two Delta IV-Medium rockets this year, one Delta IV-Heavy, and a single Atlas V mission. The company may launch Boeing's Starliner spacecraft before the end of 2019, giving the Atlas V rocket a second launch.</p>

<p>It is possible that Rocket Lab, which has flown its Electron rocket from New Zealand five times in 2019 and is planning at least one more mission before the end of the year, will have more launches than United Launch Alliance for the first time. Sometime next year, Rocket Lab should also begin to add to the US tally for orbital launches as it opens a new facility at Wallops Island, Virginia.</p>

<p><a href="https://arstechnica.com/?p=1603251&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Write AI code once, run anywhere—it’s not Java, it’s Intel’s oneAPI</title>
		<link>https://arstechnica.com/?p=1603199</link>
		<pubDate>Mon, 18 Nov 2019 12:48:16 +0000</pubDate>
		<dc:creator><![CDATA[Jim Salter]]></dc:creator>
				<category><![CDATA[Tech]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[machine learning]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1603199</guid>
		<description><![CDATA[OneAPI unifies code across multiple hardware targets—like Nvidia and Intel GPUs.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/oneAPI-heroes-800x348.png" alt="Intel's &quot;Mega Trends in HPC&quot; boil down to AI workloads, running on many kinds of hardware, largely in cloud—not on-premise—environments."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/oneAPI-heroes.png" class="enlarge-link" data-height="413" data-width="950">Enlarge</a> <span class="sep">/</span> Intel's &quot;Mega Trends in HPC&quot; boil down to AI workloads, running on many kinds of hardware, largely in cloud—not on-premise—environments. (credit: Intel Corporation)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Saturday afternoon (Nov. 16) at Supercomputing 2019, Intel launched a new programming model called oneAPI. Intel describes the necessity of tightly coupling middleware and frameworks directly to specific hardware as one of the largest pain points of AI/Machine Learning development. The oneAPI model is intended to abstract that tight coupling away, allowing developers to focus on their actual project and re-use the same code when the underlying hardware changes.</p>
<p>This sort of "write once, run anywhere" mantra is reminiscent of Sun's early pitches for the Java language. However, Bill Savage, general manager of compute performance for Intel, told Ars that's not an accurate characterization. Although each approach addresses the same basic problem—tight coupling to machine hardware making developers' lives more difficult and getting in the way of code re-use—the approaches are very different.</p>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/oneAPI-slide1.png" alt=""></div>
        <p>
          In this simplified block diagram of AI/ML development, Intel wants to isolate "Languages &amp; Libraries" as the biggest pain point.                      [credit:
                        Intel Corporation                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<p>When a developer writes Java code, the source is compiled to bytecode, and a Java Virtual Machine tailored to the local hardware executes that bytecode. Although many optimizations have improved Java's performance in the 20+ years since it was introduced, it's still significantly slower than C++ code in most applications—typically, anywhere from half to one-tenth as fast. By contrast, oneAPI is intended to produce direct object code with no or negligible performance penalties.</p>
<p>When we questioned Savage about oneAPI's design and performance expectations, he distanced it firmly from Java, pointing out that there is no bytecode involved. Instead, oneAPI is a set of libraries that tie hardware-agnostic API calls directly to heavily optimized, low-level code that drives the actual hardware available in the local environment. So instead of "Java for Artificial Intelligence," the high-level takeaway is more along the lines of "OpenGL/DirectX for Artificial Intelligence."</p>
<p>For even higher-performance coding inside tight loops, oneAPI also introduces a new language variant called "Data Parallel C++" allowing even very low-level optimized code to target multiple architectures. Data Parallel C++ leverages and extends <a href="https://www.khronos.org/sycl/">SYCL</a>, a "single source" abstraction layer for OpenCL programming.</p>
<p>In its current version, a oneAPI developer still needs to target the basic hardware type he or she is coding for—for example, CPUs, GPUs, or FPGAs. Beyond that basic targeting, oneAPI keeps the code optimized for any supported hardware variant. This would, for example, allow users of a oneAPI-developed project to run the same code on either Nvidia's Tesla v100 or Intel's own newly released <a href="https://www.tomshardware.com/news/intel-xe-ponte-vecchio-7nm-graphics-gpu">Ponte Vecchio</a> GPU.</p>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/xe-architecture-slide.png" alt=""></div>
        <p>
          Intel's 7nm Xe architecture is intended to cover the entire range of GPU applications, but Ponte Vecchio—the first Xe product—specifically targets high-end deep learning and training in datacenter and supercomputing environments.                      [credit:
                        Intel Corporation                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<p>Ponte Vecchio is the first actual product in Intel's new Xe GPU line and is targeted specifically at HPC supercomputing and data center use. Although neither Savage nor other Intel execs Ars spoke to had timelines or would speak to concrete products, one slide from Intel's Supercomputing 2019 presentation clearly shows the Xe architecture as encompassing workstation, mobile, and gaming use—so there may be interesting times ahead for rivals in those spaces.</p>
<p>Savage told Ars that although the current version of oneAPI does still require developers to code for a particular architecture family—CPU, GPU, FPGA, etc—Intel plans for a future release to also allow automatic selection of the most optimal hardware type available.</p>
<p>The oneAPI toolkit is available for use and testing now at Intel <a href="https://software.intel.com/en-us/devcloud">Devcloud</a>.</p>

<p><a href="https://arstechnica.com/?p=1603199&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Logitech’s $100 Adaptive Gaming Kit finishes what Xbox’s XAC started</title>
		<link>https://arstechnica.com/?p=1602407</link>
		<pubDate>Mon, 18 Nov 2019 08:01:37 +0000</pubDate>
		<dc:creator><![CDATA[Sam Machkovech]]></dc:creator>
				<category><![CDATA[Gaming & Culture]]></category>
		<category><![CDATA[Logitech]]></category>
		<category><![CDATA[xbox adaptive controller]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602407</guid>
		<description><![CDATA[“People buy the XAC, then ask, ‘what should go with this? ’” Logitech made the answer.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/logitech-adaptive-800x398.png" alt="The four button types included in the 12-button Logitech Adaptive Gaming Kit bundle, along with one of its two &quot;hook-and-loop&quot; mounting boards."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/logitech-adaptive.png" class="enlarge-link" data-height="425" data-width="855">Enlarge</a> <span class="sep">/</span> The four button types included in the 12-button Logitech Adaptive Gaming Kit bundle, along with one of its two &quot;hook-and-loop&quot; mounting boards. (credit: <a rel="nofollow" class="caption-link" href="https://www.logitech.com/en-us">Logitech</a>)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Last year's <a href="https://arstechnica.com/gaming/2018/09/xbox-adaptive-controller-retail-impressions-a-bold-start-for-limited-gamers/" target="_blank" rel="noopener">Xbox Adaptive Controller (XAC)</a> heralded a new era of gaming accessibility, but not necessarily in conclusive fashion. What Microsoft's specially engineered slab of a controller delivered in options and openness, particularly for gamers who can't use standard gamepads, the device lost in clarity.</p>
<p>The $99 XAC only comes with two useful buttons for standard PC and console games, and Microsoft said that was by design so that special-needs gamers could attach preferred buttons and control options into an array of 19 plugs. This was great news for anybody familiar with the wild world of accessible gaming or who already owned extra attachable buttons. But trouble arose, accessory-maker Logitech says to Ars Technica, when XAC's good press and popularity drew new, confused people into the fold—and into official Microsoft Stores, to boot.</p>
<p>"We talked to Microsoft retail—to people in the Microsoft Stores—and they kept telling us, 'We don't know what to recommend to people,'" Logitech Product Manager Mark Starrett tells Ars Technica. "People buy an XAC, then ask, 'What [buttons] should go with this?' The guy at the store can't assess the needs. The caregiver doesn't know [from a gaming standpoint], either."</p>
<h2>Turning “variable” into a constant</h2>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/Image-2-980x655.jpg" alt=""></div>
        <p>
          Comes with everything seen here. One of the mounting boards is rigid, while the other includes multiple folding points, like a standard tablet cover.                      [credit:
                        <a href="https://www.logitech.com/en-us">Logitech</a>
                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<p>That changes this week with the <a href="https://fave.co/2OmUhn9" target="_blank" rel="noopener">Logitech Adaptive Gaming Kit</a>, which is a $99 bundle that begins answering that basic question for Logitech's estimated "80%" of special-needs gamers. Logitech offered Ars Technica a pre-brief about the bundle before shipping us a sample set, so we cannot speak to its build quality or whether it's a worthy purchase.</p>
<p>Still, based on my testing and research since the XAC launched, I'm already compelled to applaud Logitech's launch, at least in terms of apparent value and usability.</p>
<p>The crux of the Adaptive Gaming Kit is a suite of 12 discrete buttons that connect via XAC's 3.5mm ports. It's easier to parse them as a list:</p>
<ul>
<li>Three round buttons, 2.6-inch diameter</li>
<li>Three round buttons, 1.4-inch diameter</li>
<li>Four "light-touch" buttons</li>
<li>Two "variable" triggers</li>
</ul>
<p>Most articles about <a href="https://arstechnica.com/gaming/2018/05/xbox-adaptive-controller-a-bold-answer-to-the-tricky-world-of-accessible-gaming/" target="_blank" rel="noopener">XAC's launch</a> included photos of these kinds of buttons, with the idea being that users with various disabilities or needs would buy each one a la carte to add more functionality beyond the XAC and a nearby default Xbox One controller. But it doesn't take long to reach a $99 spending threshold at 3-4 buttons, which barely covers the entirety of a standard game's functions. On a sheer price level, Logitech has done the right thing. Target XAC users will likely need no fewer than four discrete buttons, so you're saving money compared to the rest of the fray by going with Logitech's set.</p>
<p>On top of that, Logitech includes two hook-and-loop boards and relevant connecting cables in this bundle. XAC users will likely want to mount extra buttons onto these kinds of boards so that they can remain more stable while near a controlling body part of choice: a foot, a fingerless hand, even a head. And they're a perfect freebie bonus for a set that's already reasonably priced.</p>
<p>To top all of that off, the included "variable" triggers play nicely with XAC's pair of analog 3.5mm ports. Most 3.5mm controller accessories only offer binary "on/off" switch functionality. That's fine for most controller functions but not for one that Logitech identified as a popular genre for special-needs gamers: racing.</p>
<p>"If you look around the [special needs] market... I haven't successfully found a good variable trigger replacement," Starrett says. "If you wanted to use gas and brake in <a href="https://arstechnica.com/tag/forza/" target="_blank" rel="noopener"><em>Forza</em></a>, stuff like that, there was no solution. Just binary digital buttons. So we include two of those in the kit. I'm a racer, and so are a lot of people we met. They want to play these games and struggle with this insane, 100% throttle thing."</p>
<h2>From 200 joysticks to 99 dollars</h2>
<p>Logitech says this project began on the side when Microsoft began asking for loaner joysticks a few years ago to test a secret project. (Starrett says they gave more than 200 joysticks to that aim before finding out what the XAC actually was.) Logitech's design team was looped into the shape, connection protocols, and launch plans for the XAC ahead of its launch, but the team didn't realize how many steps were left open for potential buyers, in terms of additional buttons, until after launch.</p>
<p>"I'm not gonna blind-read [the Xbox team]'s positions, but they don't make a lot of peripherals traditionally," Starrett says. "They make their controllers and consoles. They don't want to be in the peripheral business at this level, I don't think. Meanwhile, we're very expert in this area. We've done many things with Microsoft, we've supported their platforms for years. It was a natural thing [to team up on an adaptive controller bundle]. They might've gone and made one themselves if we hadn't said, 'We're going to do this and work with you.'"</p>
<p>Hence, Microsoft handed Logitech its Rolodex for special-needs gaming researchers and experts, including the UK non-profit Special Effect, a rehab center at Mt. Sinai Hospital, and XAC engineering lead Bryce Johnson. From that point on, Logitech spent the next year designing the controllers while "shaving down the profit margins" to get the bundle's price point to $99. The resulting bundle is now on sale at <a href="https://fave.co/2OmUhn9" target="_blank" rel="noopener">logitechg.com</a> and at most American Microsoft Store locations; it'll come to European Microsoft Stores "if not day one, then shortly after."</p>

<p><a href="https://arstechnica.com/?p=1602407&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Watch out, Tesla—Ford gets serious with Mustang Mach-E electric crossover</title>
		<link>https://arstechnica.com/?p=1603099</link>
		<pubDate>Mon, 18 Nov 2019 02:30:19 +0000</pubDate>
		<dc:creator><![CDATA[Jonathan M. Gitlin]]></dc:creator>
				<category><![CDATA[Cars]]></category>
		<category><![CDATA[battery electric vehicle]]></category>
		<category><![CDATA[Ford Mustang Mach-E]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1603099</guid>
		<description><![CDATA[The Mach-E range starts at $43,895 with deliveries starting in late 2020.]]></description>
				<content:encoded><![CDATA[





<div><a name='page-1'></a></div>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/Mustang-Family-Photo-980x551.jpg" alt=""></div>
        <p>
          Ford wanted its first long-range EV to be unambiguously a Ford, so it decided to make it a Mustang.                       [credit:
                        Ford                        ]
                  </p>
        </div>
      </li>
      </ul>
  


<p>LOS ANGELES—The electric car market is about to get extremely interesting. After what feels like an interminable wait, the battery EV may soon finally cross over from <a href="https://driving.ca/auto-news/news/electric-car-sales-have-now-surpassed-stickshift-sales-in-the-u-s">curio to the big time</a> as a slew of new models arrive in 2020. Each targets the all-important crossover buyer, and all in roughly the same $40,000 to $60,000 price range. After slurping up <a href="https://www.bloomberg.com/graphics/2019-tesla-model-3-survey/market-evolution.html">most everyone's sporty sedan sales</a>, Tesla will start shipping the <a href="https://arstechnica.com/cars/2019/03/at-a-quick-los-angeles-event-tesla-announces-the-300-mile-range-model-y/">Model Y</a>. Volkswagen will reveal its ID.4 on Tuesday at the LA Auto Show, and the <a href="https://arstechnica.com/cars/2019/09/this-is-volkswagens-new-e30000-electric-car-the-id-3/">MEB-based BEV</a> is destined for US production in Chattanooga, Tennessee. Volvo's <a href="https://arstechnica.com/cars/2019/10/volvos-xc40-crossover-goes-fully-battery-electric-for-under-48000/">excellent XC40 crossover</a> is getting a big-old battery pack and shares its tech with <a href="https://arstechnica.com/cars/2019/02/volvo-spinoff-polestar-reveals-its-battery-ev-the-polestar-2/">the exciting Polestar 2</a>. And then there's the Ford Mustang Mach-E, which made its formal debut at a live-streamed event on Sunday evening.</p>
<h2>Compliance car to Mustang</h2>
<p>It was <a href="https://arstechnica.com/cars/2019/11/ford-opens-its-order-books-for-mustang-mach-e-electric-crossover/?comments=1&amp;start=0">a contentious move</a>, using the Mustang brand. It wasn't the plan, either—not at first. Originally Ford was working on what it openly described as "a compliance car," one built simply to meet incoming emissions rules in the US and Europe. But in 2017 it threw out those plans, putting together an internal skunk works called Team Edison with a brief to reimagine the project. Its goal was to design a BEV that could only be a Ford, and there's little that's more iconically Ford than the galloping pony.</p>
<p>In just over a year, and with heavy reliance on VR instead of clay models, Team Edison pulled at the shape to get away from a more generic take on the crossover. The main electric motor moved from the front of the car to the rear. The wheelbase grew by 8.5 inches (216mm), and the dash-to-axle ratio was lengthened. The A-pillar was pulled back toward the rear of the car, lengthening the hood line, and there's a clever visual trick with the roof rails that really works to place the Mach-E within the Mustang family when you see the car in profile or from the rear three-quarter angle.</p>
<p>It's a more challenging design seen head-on. The headlights shout 'Stang, as do the creases that run the length of the hood. But it can also look a bit tall and narrow, particularly when painted in darker colors. The best-looking variant is the Mach-E GT, set to show up in spring 2021. This has unique front styling, with optimized aerodynamics and a polycarbonate insert that ticks the box in your brain that expects to find a grille at the front of a car. None of the engineers would get specific beyond telling us that the Mach-E's drag coefficient was "below 0.3."</p>
<h2>Tesla's influence is clear</h2>
<p>The timing of Team Edison's tearing up of the compliance car does not seem accidental. (Nor does the choice of the Los Angeles Jet Center as the site of the reveal; it is <em>literally</em> next door to SpaceX in Hawthorne, California.) <a href="https://arstechnica.com/cars/2017/07/pared-down-electric-experience-driving-one-of-the-first-model-3s-off-the-line/">2017</a> was when the first Tesla Model 3s reached the public, and that car's influence on the Mach-E is clear the moment you open a door and step inside. A door you open by pushing a button; door handles are too <em>passé</em> here.</p>
<p><a href="https://arstechnica.com/cars/2019/03/the-tesla-model-3-reviewed-finally/">Like the Model 3</a>, it's basically a button-free zone. The center stack is dominated by a 15.5-inch touchscreen, portrait-style and proud on the dash. It runs Ford's latest QNX-based Sync 4, with an elegant and intuitive tile-based UI that shares design principles with both Tesla's and Volvo's latest infotainment systems. At the bottom of the screen is a physical jogwheel overlaid atop the screen, similar to the ones you find in Jaguar Land Rover's Touch Duo setups. Right now this is just set up to be a dedicated volume control, although it's easy to see how Ford could add more functionality to it as an input device through a later OTA update.</p>
<p>The Mach-E addresses a key complaint of ours when it comes to the Model 3 by providing a second dedicated instrument panel directly in front of the driver. Ford has been remarkably restrained with its use of this 10.2-inch digital display—it will show you your speed, range, and some other critical information, but not much else.</p>
<p>We weren't allowed to drive the Mach-E, but I did get a brief ride in one. The back seat is roomy—far more spacious than a Jaguar I-Pace—and bright and airy because of a full-length glass roof. Thoughtful design details abound; the arm rest between the driver and passenger folds up to provide the perfect place to stash your purse or man-bag, and the 4.8-cubic-foot (135L) frunk will have a drain hole, so if you want to fill it with ice at a tailgate, you can. (Open up the actual tailgate and the rear has 29 cubic feet/821L of cargo volume with the rear seats in use.)</p>
<h2>Five models to rule them all?</h2>
<p>Between late 2020 and spring 2021, Ford will bring out a mix of rear- and all-wheel drive Mach-Es with either standard- or extended-range battery packs. The cheapest of these is the Select; $43,895 buys you a rear-driving one of these with the smaller pack, but you'll have to wait until early 2021 to get one of those. That also applies to the $52,400 California Route 1, a RWD version with lower-drag 18-inch wheels and the long-range battery pack. All prices are before the IRS tax credit is taken into account; this will be $7,500 until Ford joins <a href="https://arstechnica.com/cars/2018/07/tesla-sold-200000-cars-in-the-us-so-the-7500-tax-credit-is-going-away/">Tesla</a> and <a href="https://arstechnica.com/cars/2019/01/gm-sold-200000-electric-vehicles-by-q4-2018-reuters-source-says/">General Motors</a> in having sold 200,000 plug-ins, at which point it will begin to sunset. Ford expects this to happen at some point in 2021.</p>
<p>If you want a Mach-E in 2020, it will have to be either a Premium—starting at $50,600 in standard-range, RWD spec—or the $59,900 First Edition, which combines AWD and the big battery. The big battery is also found in the Mach-E GT. This arrives last and trades range for performance—Ford is targeting a sub-4 second 0-60mph time for the $60,500 Mach-E GT, and there will be a Performance pack that drops this time into the mid 3-second range. Based on a brief ride in a development car—one that was "60-70% of the way to sign-off," according to the engineer—even the all-wheel drive Premium models should be accelerative enough to thrill most drivers trading internal combustion for electric propulsion.</p>
<p>Speaking of, the motors are an in-house Ford design, evolved from the company's experience with its hybrid line up. Both front and rear motors use permanent magnets, <a href="https://arstechnica.com/cars/2019/09/everything-you-wanted-to-know-about-porsches-new-electric-car/">and like Porsche</a>, Ford has gone for a rectangular hairpin design for the coils that packs more copper and less air inside. The amount of power and torque depends on configuration; at the low end, a Mach-E Select should be about 190kW (255hp), and 419Nm (306lb-ft) for a RWD model. Ford's target for the AWD First Edition is 248kW (332hp) and 565Nm (417lb-ft), and 342kW (459hp) and 830Nm (612lb-ft) from the GT.</p>
<h2>300 miles should end range anxiety</h2>
<p>For the battery pack, Ford is using pouch cells from LG Chem, built into modules that are then combined in series and parallel. The smaller pack uses 288 cells in 10 modules to offer 75.7kWh, which should provide 210-230 miles (338-370km) of range depending on whether it's a single- or dual-motor Mach-E.</p>
<p>The larger pack is 98.9kWh, made from 12 modules of 376 cells. That's a lot of energy to play with, and Ford thinks that will be sufficient for 300 miles (482km) when fitted to a rear-wheel drive Mach E, which should go a long way to countering range anxiety. DC fast-charging one of those at 150kW should take the battery state of charge from 10 to 80% in 38 minutes.</p>
<p>Home charging is obviously a lot slower; about 22 miles per hour (35km/h) when connected to the standard 240V, 32A charger, or 32 miles each hour if you spring for the optional 48A wallbox. Like Audi and Porsche, Ford is partnering with Amazon to make the home installation process as painless as possible, and it's working with Electrify America and Greenlots to create a Ford Pass charging network of 12,500 public chargers, which should support plug-and-charge, where the car authenticates your account details with the charger as part of the handshake procedure.</p>
<p>Tesla's influence on Team Edison is also on display when it comes to buying a Mach-E. You can do that through a Ford dealer—2,100 in the US are certified to sell and service EVs, and each will have cars on hand to provide test drives. But Ford also wants you to be able to buy a Mach-E online, easily, without the normal song-and-dance routine that is the American car-buying experience. Exactly how that will work is still being determined since long-standing protectionist laws exist in most states that mandate that a dealer gets a cut when someone wants to buy a new car.</p>

<p><a href="https://arstechnica.com/?p=1603099&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>California’s methane super-emitters</title>
		<link>https://arstechnica.com/?p=1597207</link>
		<pubDate>Sun, 17 Nov 2019 15:00:07 +0000</pubDate>
		<dc:creator><![CDATA[Diana Gitig]]></dc:creator>
				<category><![CDATA[Science]]></category>
		<category><![CDATA[California]]></category>
		<category><![CDATA[climate]]></category>
		<category><![CDATA[dairies]]></category>
		<category><![CDATA[methane]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1597207</guid>
		<description><![CDATA[In the Golden State, landfills are the worst, then dairies and the oil/gas sector. 
]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/Screen-Shot-2019-11-16-at-12.21.48-PM-800x322.png" alt="Seagulls attack a garbage heap."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/Screen-Shot-2019-11-16-at-12.21.48-PM.png" class="enlarge-link" data-height="472" data-width="1171">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="https://www.oregonmetro.gov/news/greater-portland-garbage-will-no-longer-go-growing-landfills">Oregon Metro</a>)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Methane is a much more potent greenhouse gas than carbon dioxide, trapping much more heat. Point-source methane emitters are typically small—usually less than 10 meters in diameter—but they emit plumes of highly concentrated methane. So if we want to reduce the amount of methane we’re spouting into the air (which we obviously should, although <a href="https://arstechnica.com/tech-policy/2019/08/trump-admin-announces-plan-to-kill-2016-methane-emissions-limits/">we’re not</a>), they’d be great potential targets. If only we could identify them.</p>
<p>To map such point emissions, scientists in California flew over the state with an airborne imaging spectrometer, using it to measure methane emissions. They focused on a long list of potential sources: oil and gas production, processing, transmission, storage, and distribution equipment; refineries; dairy-manure management sites; landfills and composting facilities; wastewater-treatment plants; gas-fired power plants; and liquified and compressed natural gas facilities.</p>
<p>Most facilities, especially the dairies and the oil fields, were in the San Joaquin Valley. The researchers ended up measuring emissions from 564 distinct sources at 250 different facilities. These point emitters had not really been examined before, because they often only belch out their methane intermittently or in a somewhat sporadic manner. To catch them in the act, the researchers repeated the flyovers five times between August 2016 and October 2018.</p>
<p>They conclude that roughly 40% of California’s methane emissions come from these point-source emitters rather than larger, more diffuse sources, like rice fields. Over half of point-source emissions come from only 10% of the sites.</p>
<p>Landfills were the worst, followed by dairies and the oil and gas sector. A previous analysis that used atmospheric measurements rather than airborne imaging spectrometry reversed the relative contributions of landfills and dairies, leading the authors of this more recent work to suggest that other emission sectors may have also been improperly estimated in that earlier assessment. The authors also highlight that, perhaps not shockingly, “Large discrepancies are observed between many of the self-reported emissions from participating facilities and [this airborne imaging study] and independent airborne estimates.”</p>
<p>The good news is that when the scientists simply told the facilities operators that they possessed methane super-emitters, they were often able to reduce the emissions. Four such cases were due to leaking liquefied natural gas storage tanks; this study found the leaks and told the operators, who then repaired them. Further flyovers confirmed that the repairs halted the emissions. This constant monitoring of both point emitters and more widely distributed low-level emitters could definitely help mitigate methane emissions. As could <a href="https://grist.org/article/the-answer-to-climate-killing-cow-farts-may-come-from-the-sea/?utm_medium=email&amp;utm_source=newsletter&amp;utm_campaign=daily">feeding seaweed to cows</a>.</p>
<p>Nature, 2019. DOI: <a href="http://dx.doi.org/10.1038/s41586-019-1720-3">10.1038/s41586-019-1720-3</a> (<a href="http://arstechnica.com/ science/news/2010/03/dois-and-their-discontents-1.ars">About DOIs</a>).</p>

<p><a href="https://arstechnica.com/?p=1597207&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Google Pixel 4 review—Overpriced, uncompetitive, and out of touch</title>
		<link>https://arstechnica.com/?p=1589011</link>
		<pubDate>Sun, 17 Nov 2019 14:30:36 +0000</pubDate>
		<dc:creator><![CDATA[Ron Amadeo]]></dc:creator>
				<category><![CDATA[Features]]></category>
		<category><![CDATA[Tech]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1589011</guid>
		<description><![CDATA[It's the fourth generation now, yet we've got to ask—what's the point of the Pixel line?]]></description>
				<content:encoded><![CDATA[





<div><a name='page-1'></a></div>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/10/72-980x735.jpg" alt=""></div>
        <p>
          The Pixel 4 XL.                       [credit:
                        Ron Amadeo                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<p>The Pixel 4 arrived on the market as one of the most leaked, most talked about smartphones of 2019. This year, Google seems like it is really trying to find something unique to offer, with new features like the Google-developed "Motion Sense" radar gesture system, face unlock, a 90Hz display, the next-gen Google Assistant, and a new astrophotography mode.</p>
<p>At the prices Google is asking, though, the Pixel 4 is hard to recommend. The company saddled the phone with an ultra-premium price tag, but the Pixel 4 can't compete with ultra-premium phones. The phone falls down on a lot of the basics, like battery life, storage speed, design, and more. The new additions like face unlock and Motion Sense just don't work well. It seems like Google just cut too many corners this year.</p>
<p>The strongest feature of the Pixel line—the camera—hasn't really gotten better, either. The camera sensor is the same as last year, and the big new software feature, astrophotography mode, is also available on older Pixel devices and the much cheaper Pixel 3a.</p>
<p>The Pixel 4 isn't bad in a vacuum, but the rest of Google's Android competition gets better every year, while Google stands still. This year, Google turned in a weak, timid update to its flagship smartphone, and I'm not sure who to recommend this to at $800 or $900. Google just can't do premium right. So, when can we have the Nexus line back?</p>
<h3 data-no-jump>Table of Contents</h3>
<ul class="toc">
      <li class="depth-2">
                <a href="#h1">Design and build quality</a>
      </li>
              <li class="depth-3">
                <a href="#h2">The Pixel 4's terrible value proposition</a>
      </li>
          <li class="depth-3">
                <a href="#h3">Face unlock&mdash;Slow, unreliable, and frustrating</a>
      </li>
              <li class="depth-3">
                <a href="#h4">Motion Sense with Project Soli&mdash;Not at all what was promised</a>
      </li>
          <li class="depth-3">
                <a href="#h5">The next-gen Google Assistant</a>
      </li>
              <li class="depth-2">
                <a href="#h6">Camera&mdash;Pretty much the same as the Pixel 3</a>
      </li>
          <li class="depth-2">
                <a href="#h7">What is the point of the Pixel line?</a>
      </li>
          <li class="depth-3">
                <a href="#h8">The Good</a>
      </li>
          <li class="depth-3">
                <a href="#h9">The&nbsp;Bad</a>
      </li>
          <li class="depth-3">
                <a href="#h10">The&nbsp;Ugly</a>
      </li>
        </ul>

<h2>Design and build quality</h2>
<p>We'll start with the best part of the Pixel 4: the back. The Pixel 4 is, as usual, a glass and aluminum sandwich, with a Gorilla Glass 5 front, an aluminum frame exposed along the sides, and a glass back. When we talk about the rear design of the Pixel 4, note that between the three available colors, there are two totally different finish options that greatly affect the feel of the device.</p>
<p>The black version has a standard glossy glass back that uses Gorilla Glass 5, and the black version feels like the usual slippery fingerprint magnet that all glass phones are. The white and orange colors use a different glass panel that isn't Gorilla Glass, though, and these get a special soft-touch treatment. While this soft-touch glass back might be reminiscent of the soft-touch back on the Pixel 3 last year, this year there have been a number of improvements.</p>
<table class="specifications right" width="320">
<tbody>
<tr>
<th style="text-align: center" colspan="3">SPECS AT A GLANCE</th>
</tr>
<tr>
<th></th>
<th>Pixel 4</th>
<th>Pixel 4 XL</th>
</tr>
<tr>
<th>SCREEN</th>
<td>2280×1080 5.7-inches (440 ppi)</p>
<p>OLED, 19:9 aspect ratio</td>
<td>3040×1440 6.3-inches (523ppi)</p>
<p>OLED, 19:9 aspect ratio</td>
</tr>
<tr>
<th>OS</th>
<td colspan="2">Android 10</td>
</tr>
<tr>
<th>CPU</th>
<td colspan="2">Eight-core Qualcomm Snapdragon 855</p>
<p>Four Cortex A76-based cores (One 2.84GHz, three 2.41Ghz) and four Cortex A55-based cores at 1.78GHz</td>
</tr>
<tr>
<th>RAM</th>
<td colspan="2">6GB</td>
</tr>
<tr>
<th>GPU</th>
<td colspan="2">Adreno 640</td>
</tr>
<tr>
<th>STORAGE</th>
<td colspan="2">64GB or 128GB</td>
</tr>
<tr>
<th>NETWORKING</th>
<td colspan="2">802.11b/g/n/ac 2x2, Bluetooth 5.0 + LE, GPS, NFC, eSIM</td>
</tr>
<tr>
<th>Bands</p>
<p>(NA model)</th>
<td colspan="2"><strong>GSM:</strong> 850, 900, 1800, 1900</p>
<p><strong>UMTS/HSPA: </strong>1, 2, 4, 5, 8<br />
<strong>CDMA:</strong> BC0, BC1, BC10<br />
<strong>LTE: </strong>1, 2, 3, 4, 5, 7, 8, 12, 13, 14, 17, 18, 19, 20, 25, 26, 28, 29, 30, 38, 39, 40, 41, 46, 48, 66, 71</td>
</tr>
<tr>
<th>PORTS</th>
<td colspan="2">USB Type-C 3.1 Gen 1</td>
</tr>
<tr>
<th>CAMERA</th>
<td colspan="2">Rear: 12MP main camera, 16MP telephoto (x2)</p>
<p>Front: 8MP camera</td>
</tr>
<tr>
<th>SIZE</th>
<td>147.1×68.8×8.2 mm</td>
<td>160.4×75.1×8.2 mm</td>
</tr>
<tr>
<th>WEIGHT</th>
<td>162g</td>
<td>193g</td>
</tr>
<tr>
<th>BATTERY</th>
<td>2800mAh</td>
<td>3700mAh</td>
</tr>
<tr>
<th>STARTING PRICE</th>
<td><a href="https://goto.walmart.com/c/1305166/565706/9383?u=https%3A%2F%2Fwww.walmart.com%2Fip%2FGoogle-Pixel-4-Black-64-GB-Unlocked%2F925508836&amp;subid1=Pixel4Review" target="_blank" rel="noopener">$799</a></td>
<td><a href="https://goto.walmart.com/c/1305166/565706/9383?u=https%3A%2F%2Fwww.walmart.com%2Fip%2FGoogle-Pixel-4-XL-Black-64-GB-Unlocked%2F419637576&amp;subid1=Pixel4Review" target="_blank" rel="noopener">$899</a></td>
</tr>
<tr>
<th>OTHER PERKS</th>
<td colspan="2">USB-PD quick charging, face unlock, IP68 dust and water resistance, Active Edge, Pixel Neural Core, Titan M security module</td>
</tr>
</tbody>
</table>
<p>First, the new soft-touch backs can no longer be dented by a fingerprint, and they feel noticeably more durable than the soft-touch coating on the Pixel 3. Second, while the Pixel 3 coating tended to <a href="https://arstechnica.com/gadgets/2018/10/pixel-3-xl-review-great-software-but-google-just-isnt-a-hardware-leader/#h3">absorb and hold onto</a> fingerprint grease, the Pixel 4 hides fingerprints very well. The soft-touch Pixel 4 back looks and feels clean all the time, and I'm not compelled to scrub it down with soap and water every five minutes like with the Pixel 3.</p>
<p>I'd rather we just not make phones out of glass at all, but if we have to, the soft-touch coating on the white and orange Pixel 4 really is the best in the market. The back provides an agreeable amount of grip that you don't get with regular glass. It looks great, it stays clean, and it seems durable. This is one of the few parts of the Pixel 4 that is different <em>and better</em> than the competition, and I hope other manufacturers copy the soft-touch implementation here.</p>
<p>The entire back of the Pixel 4 is great, actually. This year, Google jumped on the multi-camera bandwagon and added a 16MP telephoto lens. The whole camera assembly—which includes an LED flash, microphone, and spectral/flicker sensor—now lives in a big black square tucked neatly into the corner of the phone. It's a similar solution to the iPhone 11, but I daresay Google's camera block looks better. In person the black interior does a good job of hiding the clutter of the camera hardware, which I think looks cleaner than the purposefully highlighted lenses of the iPhone 11. People love to imagine shapes in these camera assemblies, so if the iPhone 11 Pro camera block looks like a <a href="https://twitter.com/marveldown/status/1171448780895338496">stovetop</a> or <a href="https://www.reddit.com/r/funny/comments/d2pbsr/iphone_11_pro_vs_fidget_spinner/">fidget spinner</a>, the Pixel 4 looks like a shocked robot or <a href="https://knowyourmeme.com/memes/surprised-pikachu">Pikachu face</a>. Thanks to the black interior, though, the Pixel 4 is considerably more subtle about it.</p>
<p>The black camera block provides a pleasing contrast to the white or orange backs, and the black ring around the perimeter of the phone ties it all together pleasantly. The back really is handsome. While the sides are eventually aluminum, you won't be touching any bare metal when you hold the Pixel 4. The sides have what Google calls a "matte finish hybrid coating," which just feels like a hard plastic shell. It doesn't seem any grippier than anodized aluminum, so I'm not sure why Google bothered.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/10/4-2.jpg"><img alt='The many sensors in the Pixel 4&#039;s top bezel.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/10/4-2-980x494.jpg" alt='The many sensors in the Pixel 4&#039;s top bezel.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/10/4-2.jpg"class="caption-link" rel="nofollow">The many sensors in the Pixel 4's top bezel.</a> (credit: Ron Amadeo / Google)</p></div>
<p>As usual, the front design for the Pixel line looks dated this year. The Pixel 4 has a sizable bezel only on the top of the device, which gives the phone a lopsided, top-heavy look. Most phones have aimed to reduce the bezels as much as possible, going for only a minimal camera blemish or, sometimes, no <a href="https://arstechnica.com/gadgets/2019/05/oneplus-7-pro-review-the-fastest-best-designed-best-value-android-phone/">blemish at all</a>. But not Google. The Pixel 4 design reminds me of the Galaxy S8, a phone that came out two years ago, and the stats back that up. The Pixel 4 has an 81.3% screen-to-bezel ratio, while the Galaxy S8 has a more efficient use of space, with an 83.6% screen-to-bezel ratio.</p>
<p>The top bezel might look like something from 2017, but it <em>is</em> being put to use, as Google is packing the top of the phone with sensors and features. Besides the normal 8MP selfie camera, earpiece, and ambient light/proximity sensor, there's a whole system for 3D face unlock, which uses two IR cameras, an IR dot projector, and an IR flood illuminator. There's also a Google-developed Soli radar sensor, which is used to detect air gestures above the phone as well as the user's presence.</p>
<p>Among the biggest upgrades in the Pixel 4 this year is the addition of a 90Hz OLED display. Faster refresh-rate displays are quickly becoming the new trend in smartphone design, with Razer, Asus, OnePlus, and a few other Chinese brands getting in on the action. We loved the 90Hz displays on the <a href="https://arstechnica.com/gadgets/2019/05/oneplus-7-pro-review-the-fastest-best-designed-best-value-android-phone/">OnePlus 7 Pro</a> and <a href="https://arstechnica.com/gadgets/2019/10/oneplus-7t-review-not-very-new-but-still-one-of-the-best-phones-you-can-buy/">7T</a>, where the higher refresh rate and FPS made scrolling, animations, and navigation feel buttery smooth.</p>
<p>If we were huge fans of the OnePlus' 90Hz display, then we have to be huge fans of Google's 90Hz display, right? Well, not so much, as Google's 90Hz display doesn't run at 90Hz all the time. Like many new features on the Pixel 4, the 90Hz display sounds good on paper, but in reality, it comes with myriad gotchas.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/10/Screenshot_20191023-111036.png"><img alt='The Pixel 4&#039;s 90Hz display setting only works &quot;for some content.&quot; '  src="https://cdn.arstechnica.net/wp-content/uploads/2019/10/Screenshot_20191023-111036-980x485.png" alt='The Pixel 4&#039;s 90Hz display setting only works &quot;for some content.&quot; ' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/10/Screenshot_20191023-111036.png"class="caption-link" rel="nofollow">The Pixel 4's 90Hz display setting only works "for some content." </a> (credit: Ron Amadeo)</p></div>
<p>Not running in 90Hz all the time is justifiable in some cases. If you're running a full-screen video at 24fps, 30fps, or 60fps, a 90Hz refresh rate won't do anything other than burn battery. Some games are not compatible with 90Hz, so limiting the display there is appropriate, too. The Pixel 4 goes much further than this, though, and <a href="https://9to5google.com/2019/10/25/google-pixel-4-disables-90hz-display-apps/">turns off 90Hz</a> any time you use Google Maps, Waze, WhatsApp, and Pokémon Go. Pokémon Go is a game that is limited to 30fps, so that's fine. WhatsApp was blacklisted by Google "due to poor performance under 90hz" according to an <a href="https://android.googlesource.com/device/google/coral/+/3b983fb146f8f124c01a1b5170eb9f6fc8d8f9d4">Android commit.</a> Google Maps and Waze, Google's two mapping apps, don't really have an explanation attached as to why they are limited to 60fps on the Pixel 4. We can only assume it's because Waze and Maps are already battery-heavy apps, and Google is worried about the Pixel 4's battery life.</p>
<p>The <a href="https://arstechnica.com/gadgets/2019/10/the-pixel-4s-refresh-rate-is-inexplicably-tied-to-its-display-brightness/">second big refresh rate</a> issue is that the 90Hz mode is tied to the phone's... brightness? Shortly after the phone hit the market, users discovered that, depending on the ambient light, the Pixel 4 would run in 90Hz mode when above 75% brightness and drop to 60Hz when below 75%. Google PR responded to this discovery, saying the behavior was "preserving battery when higher refresh rates are not critical." <a href="https://www.xda-developers.com/google-pixel-4-why-90hz-limited-brightness/">XDA</a> did some digging and <a href="https://android.googlesource.com/platform/frameworks/base/+/bc841b029311400ef2602bafe9b3776310d5e8a7">found</a> the Android source commit for this behavior, which explains that "Due to [a] hardware limitation, flickers are seen when switching between 60 and 90Hz at low display and ambient brightness." Apparently any time you're in the dark, switching from 60 to 90Hz mode would be noticeable, so Google turns off 90Hz mode completely.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/16.jpg"><img alt='Dig into the developer options and you can force 90Hz to be on all the time, just like a real flagship. '  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/16-980x249.jpg" alt='Dig into the developer options and you can force 90Hz to be on all the time, just like a real flagship. ' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/16.jpg"class="caption-link" rel="nofollow">Dig into the developer options and you can force 90Hz to be on all the time, just like a real flagship. </a> (credit: Ron Amadeo)</p></div>
<p>You can opt out of Google's 90Hz shenanigans by digging into the hidden-by-default developer settings, which you can access after entering Android's version of the Konami code (go to Settings -&gt; About Phone and tap on "build number" seven times). In here, you'll find an option to "Force 90Hz refresh rate" all the time, which then makes the Pixel 4 work like every other 90Hz phone.</p>
<p>With this developer checkbox on, the Pixel 4 matches the buttery smooth performance we've seen from other 90Hz phones: the animations, scrolling, and transitions are all faster and smoother feeling. With this checkbox off, eh, it's a crap shoot. The Pixel 4's brightness and ambient light requirements for the 90Hz mode are very high, and this seems to require bright overhead light. Just keeping the display on and wandering around my house in the daytime is enough to have it ping-pong between 60 and 90Hz. The very brightly lit bathroom with the overhead lights? That's good enough for 90Hz. The moderately lit bedroom with the lamp in the corner and light coming through the window? That's going to drop to 60Hz. Even just something like my head casting a shadow over the light sensor from an overhead light is enough to have it drop to 60Hz.</p>
<p>You know how auto brightness is totally crazy and unreliable? Now imagine that technology being used to control the refresh rate of your device. It is just all over the place based on the tiniest light fluctuations. You won't necessarily notice <em>every</em> drop from 90Hz to 60Hz, but the end result is that it happens so frequently that the Pixel 4 doesn't feel as fast or fluid as other 90Hz phones in the default mode. It really is detrimental to the experience. It's great that you can turn all these half-measures off, but the overwhelming message from Google is that its 90Hz phone doesn't have a big enough battery to support 90Hz mode all the time.</p>
<p>Google issued a patch in November that made the 90Hz mode work in <a href="https://9to5google.com/2019/11/05/pixel-4-90hz-update-test/">slightly brighter</a> conditions, but the end result has not changed much: the Pixel 4 runs in 60Hz mode most of the time.</p>
<p>The display on the Pixel 4 XL looks great in indoor lighting, but it's not very bright, and you might have issues in sunlight. There's actually a <a href="https://www.xda-developers.com/google-pixel-4-high-brightness-mode-fix/">hidden high-brightness</a> mode that was recently discovered by XDA. The display has a sunlight mode, but Google chose not to expose it to users. I would guess this is because it would use a ton of the device's limited battery.</p>
<p>This year the Pixel 4 supports "Ambient EQ," a display white balance adjustment that changes based on the surrounding light. It's basically the Google version of Apple's True Tone. Ambient EQ previously appeared on the <a href="https://arstechnica.com/gadgets/2018/10/google-home-hub-review-a-minimum-viable-product-with-potential/">Google Home Hub</a>, which came with a special hardware color sensor and aggressive automatic brightness and white balance controls. I was a big fan of the Home Hub implementation, which was so aggressive that it allowed the display to blend into the environment, completely removing the glaring, blasting light that normally comes out of a display panel. The Pixel 4 doesn't have the special color sensor and only lightly tweaks the display based on the surrounding light. It's subtle enough that it doesn't make a huge difference, and I could take it or leave it. I'm still very interested in seeing what a Home Hub-style implementation would look like on a smartphone, though.</p>
<div><a name='page-2'></a></div>
<h3>The Pixel 4's terrible value proposition</h3>
<p>When using the Pixel 4, looking at the specs, and comparing it to other devices on the market, I just can't shake the feeling that the Pixel 4 is a cheap, cut-rate device. It feels a bit like reviewing an <a href="https://arstechnica.com/gadgets/2016/06/oneplus-3-review-a-great-400-phone-you-can-actually-buy/">early OnePlus phone,</a> where the company would cut some corners to deliver a lower price, and you would have to ask "Are these the right corners to cut?" There are clearly some corners missing from the Pixel 4, but Google doesn't pass any of that hardware stinginess on to the consumer. The Pixel 4 is priced at $800 and $900 dollars—fully priced but not fully specced. For so many sub-par, uncompetitive hardware decisions, the only explanation I can come up with is "Google wanted higher profit margins."</p>
<p>Looking elsewhere in the Android universe, you can do so much better for your money. The Pixel 4 only comes with 64GB of storage, which is a storage tier most other Android manufacturers have moved on from entirely. The Galaxy S10 and the latest OnePlus phones both start at 128GB of storage, so it's fair to compare the 128GB competition not to the $800 and $900 64GB Pixel 4 and Pixel 4 XL, but to the 128GB versions that add $100 to both price tags. Apple is really the only other major company that starts its smartphones at 64GB, but there are even times when Apple offers a better value than Google. The 64GB iPhone 11 starts at $700, $100 cheaper than the Pixel 4—and, by the way, the iPhone 11 has a bigger screen <em>and</em> a bigger battery. There is even more separation at 128GB: a 128GB iPhone 11 is $750, and a 128GB Pixel 4 is $900.</p>
<p>Have we mentioned that Google is using older, cheaper UFS 2.1 flash storage in the Pixel 4? Samsung and OnePlus are already shipping UFS 3.0, which offers faster read speeds, faster app launching, and smoother, more consistent performance when background tasks are happening. The most important of those are the read speeds, which are used for loading, and the Pixel 4 gets blown away by the latest OnePlus and Samsung phones. The read speeds of the Pixel 4 are actually slower than <em>the Pixel 3</em>.</p>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/Phone-benchmark-2017.008-980x735.jpeg" alt=""></div>
        <p>
                            </p>
        </div>
      </li>
      </ul>
  

<p>The Pixel 4 only comes with 6GB of RAM, when similarly priced phones from Samsung or much cheaper phones from OnePlus have 8GB or 12GB of RAM.</p>
<p>Since Google is jumping on the multi-camera bandwagon this year, it's also worth saying that the company only ships two rear cameras. Almost everyone else ships three or four cameras at this point. I'm skeptical about the multi-camera craze, but if you're going to pitch the idea that more is better, you might as well compete. Ship at least a main camera, a wide-angle camera, and a telephoto like everyone else. But the Pixel 4 lacks a wide-angle camera. Last year, the Pixel line shipped a second, wide-angle selfie camera, but that has been cut this year, too.</p>
<p>The Pixel 4, which is supposed to be a great camera phone, is actually a bad video camera as a result. It supports 4K, 30FPS video, but not 4K 60FPS. Google was asked about this <a href="https://twitter.com/madebygoogle/status/1185736531002179584?s=19">on Twitter,</a> and the official account mentioned that 4K60 would take a lot more storage space than 4K30. Like with the limiting of 90Hz mode to protect the phone's paltry battery, here we have another feature that was turned off to protect the phone's cheap, cut-rate hardware.</p>
<p>The Pixel 4's slow-motion video mode is also pretty weak, offering only 240FPS video. The current high-speed champion is the Huawei Mate 30, which offers an astounding 7680fps video (<a href="https://www.youtube.com/watch?v=D9VPk0o05b0">which looks amazing</a>, by the way). Samsung and OnePlus only offer 960FPS, but that still puts Google, as usual, in last place. Both of these limitations work against a company that owns YouTube, the world's largest video site. You would think Google would want people out there making compelling, high-quality videos that they are eager to share with the world through its ad-supported video platform. YouTube, for the record, supports up to 8K, 60FPS video, and the platform has done so since 2015.</p>
<p>There have been profit-increasing cuts to the Pixel 4 accessories, too. The Pixel 3 and Pixel 4 don't have a 3.5mm headphone jack, but at least the Pixel 3 came with a USB-C-to-3.5mm headphone jack dongle and a set of USB-C headphones. The Pixel 4 doesn't come with either of these accessories. A lack of a 3.5mm adapter is bad in particular, because there are <a href="https://www.soundguys.com/usb-audio-explained-18563/">two competing "standards"</a> for USB-C audio, so careful compatibility research is required before buying a third-party adapter.</p>
<p>There's no <a href="https://arstechnica.com/gadgets/2018/11/802-eleventy-which-802-11ax-and-802-11ay-explained/">Wi-Fi 6</a> support, which is actually supported by the Pixel 4's Snapdragon 855 SoC. Google would have needed to add a Wi-Fi 6 RF module to the Pixel 4 to enable Wi-Fi 6, but instead Google went with a (presumably cheaper) RF module that only supports Wi-Fi 5. Wi-Fi 6 drags Wi-Fi into the modern era with foundational improvements like bi-directional communication and the ability for multiple devices to transmit at the same time. But you'll need a new router and a phone other than a Pixel 4 to try it out—for instance, like either of the last two releases from OnePlus or Samsung.</p>
<p>Google is also cutting off the cloud storage freebie that has typically come with Pixel phones. Before, photos uploaded from a Pixel phone to Google Photos would be stored at "original" quality for free, with none of the space counted against your Google account storage limit. This offer is gone from the Pixel 4, which now only offers unlimited storage for compressed "High-quality" photos. This stinginess works against the design of the Pixel 4, which puts one of the industry's best cameras on a phone with small storage options and no options for expandable storage. Before, the Pixel line seemed designed to push people toward using free cloud storage for their pictures, but now the Pixel 4 seems designed to push people to start <em>paying</em> for cloud storage. Hey Pixel 4 owners: 100GB of "Google One" cloud storage starts at just $1.99 a month! Act now while supplies last!</p>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/Phone-benchmark-2017.009-980x735.jpeg" alt=""></div>
        <p>
          Our battery tests run the Pixel 4 in 90Hz mode, because that's the only stable refresh rate available. It's also the mode that's comparable to the other 90Hz phones.                   </p>
        </div>
      </li>
      </ul>
  

<p>The place where the Pixel 4 has really been cost-cut to death, though, is the battery. The smaller Pixel 4 got the worst of it, with an absolutely microscopic 2800mAh. This is smaller than the 2915mAh in the Pixel 3, and remember, Google has added more power-hungry components, changing from a 5.5-inch, 60Hz display to a 5.7-inch 90Hz display, adding more RAM (which <a href="https://arstechnica.com/gadgets/2018/08/p-is-for-power-how-google-tests-tracks-and-improves-android-battery-life/#h3">uses more power</a>) and adding the Project Soli sensor, which is on all the time. The similarly sized Galaxy S10 has 20% more battery than the Pixel 4 with 3400mAh. Finding a Samsung flagship with this small of a battery would mean going all the way back to the Galaxy S6, which is almost five years old. We, sadly, don't have a smaller Pixel 4 to test, but the battery life is, by all accounts, a disaster. It should be a complete deal-breaker for the smaller device.</p>
<p>The Pixel 4 XL's 3700mAh battery isn't great, but it is, at least, an upgrade over the Pixel 3 XL's 3430mAh battery. The only competition Google can beat here is itself, though. Samsung has a 4100mAh battery in the comparably sized Galaxy S10+. OnePlus has a 4000mAh battery in the OnePlus 7 Pro.</p>
<p>In smartphone design, there is always an argument to be made that specs don't matter, and what genuinely matters is the device performance in the real world. The iPhone is a good example of this, which, despite often shipping smaller batteries and less RAM, still manages to have a long runtime and great performance. That's not the case with the Pixel 4, though, where Google's cost cutting negatively affects the end-user experience in the form of lower performance and cut features. The 90Hz display doesn't run in 90Hz all the time due to battery concerns, and that makes the phone feel slower than its 90Hz competition. The limited storage means the phone doesn't support 4K60FPS video, and finding a place to store all your pictures could be a challenge now that Google doesn't offer unlimited full-quality photo storage anymore. The battery is small, and the runtime is poor.</p>
<p>The thing that most concerns me about the Pixel 4, though, is longevity. Batteries degrade over time and don't hold a charge for as long. Flash memory degrades, more apps get installed, more data is generated, and the OS degrades. Day one is the best and fastest a smartphone will ever be, and the Pixel 4 already feels like it's just squeaking by to hang in the realm of "high performance smartphone." Power users are already documenting <a href="https://twitter.com/ArtemR/status/1188481871123894272?ref_src=twcamp%5Ecopy%7Ctwsrc%5Eandroid%7Ctwgr%5Ecopy%7Ctwcon%5E7090%7Ctwterm%5E3">long app hangs</a> and <a href="https://twitter.com/ArtemR/status/1188523029115981824">stuttering video</a>, and I'm sure the problem will only get worse in time. How will the Pixel 4 perform months down the line? With such little headroom available on day one, I don't think this device will have the longevity of its competition.</p>
<h3>Face unlock—Slow, unreliable, and frustrating</h3>
<p>The Pixel 4 doesn't have a fingerprint reader. Instead, for biometrics, it has a 3D face unlock system that is an outright clone of Apple's FaceID. Turn on the display, and an IR dot projector shoots an invisible grid onto your face. Dots closer to the projector are smaller than dots farther away from the projector, and two IR cameras use this dot grid to build a 3D map of your face. The final item, a "flood illuminator," is just a bright IR light that allows the face unlock system to work even in the dark. There's also a motion and Soli-activated wake feature, where if you lift the phone, or the phone senses you above it, the face unlock system will turn on automatically and unlock the phone.</p>
<p>That's all the theory, anyway. In reality, the Pixel 4's face unlock is slow, inconsistent, and frustrating to use. Security issues were discovered <a href="https://arstechnica.com/gadgets/2019/10/the-pixel-4s-face-unlock-works-on-sleeping-unconscious-people/">almost immediately</a>. It's an across-the-board regression compared to a fingerprint reader and a big downside to the Pixel 4.</p>
<p>One of the things I don't like about face unlock is that it's just so passive. With a fingerprint reader, the phone unlocks as quickly as you can press on the fingerprint reader: it feels like I'm the one using the phone, the speed is up to me, and I'm an active participant in how fast my phone is unlocking. With face unlock, I can't actively <em>do</em> anything to make it work. I just turn the screen on and stare at the lock screen, hoping it will work. Face unlock feels like I'm waiting. It feels like I'm waiting for the phone sensors to spool up and process my face, and that feels, subjectively, slow.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/24.jpg"><img alt='Face unlock setup has you rotate your head a bit to get a more complete scan.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/24-980x857.jpg" alt='Face unlock setup has you rotate your head a bit to get a more complete scan.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/24.jpg"class="caption-link" rel="nofollow">Face unlock setup has you rotate your head a bit to get a more complete scan.</a> (credit: Ron Amadeo)</p></div>
<p>The Pixel 4's face unlock is objectively slow, too. It's easy to grab a second phone and do a race-to-homescreen, and I can fingerprint unlock pretty much any phone in less time than it takes for the Pixel 4 to recognize my face. Your typical fingerprint reader goes through just one step to unlock the phone, whereas the Pixel 4's face unlock is a multi-step process. First, the Pixel 4 must light up and show the lock screen, which happens either from the (inconsistent) motion detection or from the user directly pressing the power button. Then, the face unlock sensors spin up and start recognizing your face, and if it works, you'll see the home screen.</p>
<p>Fingerprint readers don't have this two-step process. Rear-mounted capacitive fingerprint readers are always on, and in-display fingerprint readers are usually motion activated to be on most of the time, before the screen even lights up in full-power mode. Fingerprint readers also double as power buttons—even the in-display readers. A single press does everything for fingerprint unlock: it turns the display on, it processes your fingerprint, and it unlocks the phone. Most of the time you don't even <em>see</em> the lock screen on a phone with a fingerprint reader; it just shoots right to the home screen or your last app.</p>
<p>If you're pulling your phone out of your pocket or purse, you can also use fingerprint unlock sooner in the process than face unlock. Face unlock can only start working once you've lifted the phone up to your face, whereas with a fingerprint reader, you can unlock the phone before you even look at it.</p>
<p>For the frequent times when something doesn't work with Google's face unlock system, the passive nature of the interface makes it doubly infuriating to use, because it feels like there's nothing I can do to fix it. Sometimes the lift-to-wake feature just doesn't wake the phone up, and I'm left staring at a mostly blank phone because the face unlock system never turned on. Sometimes face unlock just doesn't like the angle my face is at, so I need to turn my head a bit for it to recognize me. Sometimes face unlock is disabled by the system for security reasons, like after a reset. In all of these situations, I can only start to take a corrective action after a few seconds of waiting. Since this is a passive system, and I have no idea what is going on behind the scenes, it always takes a few seconds for me to realize "oh, it didn't work again" before I can try to take some action to make it work.</p>
<p>All of these speed advantages for fingerprint unlock are just a matter of seconds, but that's a huge deal for something you do dozens of times a day. Unlocking a smartphone is the first thing you do every time you use your phone. And since unlocking is a requirement to use every other function on your phone, that means unlocking is also the most frequently used function on your phone. It is not OK for the unlocking process to have regressed as much as it has on the Pixel 4. Unlocking is something a phone has to get exactly right, and unlocking the Pixel 4 is just frustrating, slow, and inconsistent.</p>
<p>If you use any third-party apps that normally hook into the fingerprint reader, like financial apps, you'll run into compatibility issues with the Pixel 4's face unlock. The fingerprint API has been around since <a href="https://arstechnica.com/gadgets/2015/10/android-6-0-marshmallow-thoroughly-reviewed/6/#h1">Android 6.0 Marshmallow</a>, and in these four years, plenty of apps have picked up support for it. That API does not support a face unlock system, though, so in Android 10, face unlock (and generic biometric support) was added to a new <a href="https://arstechnica.com/gadgets/2019/09/android-10-the-ars-technica-review/8/#h4">"biometrics" API</a>. Since most apps support the older fingerprint API and not the newer biometrics API, you won't be able to use face unlock with them.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/25.jpg"><img alt='The face unlock settings, and unlocking Google Pay with face unlock. '  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/25-980x857.jpg" alt='The face unlock settings, and unlocking Google Pay with face unlock. ' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/25.jpg"class="caption-link" rel="nofollow">The face unlock settings, and unlocking Google Pay with face unlock. </a> (credit: Ron Amadeo)</p></div>
<p>Since unlocking a phone is so critical to the user experience, I have to ask, why doesn't the Pixel 4 have both options? Why isn't there a fingerprint reader <em>and</em> a face unlock system? Again, this is the most frequently accessed function of a phone. Unlocking is a prerequisite to do anything else, and phone manufacturers should absolutely invest a ton of money in making unlocking work as swiftly and securely as possible.</p>
<p>Samsung's Galaxy S8 and S9 shipped both iris scanners and fingerprint scanners on a single phone, and OnePlus offers selfie camera face unlock in addition to the fingerprint scanner. You can argue about the security merits of each of these biometric implementations, but the multi-biometric idea is absolutely the right way to go. Give me a passive and active form of biometric identification, and let there be a race-to-unlock between the fingerprint reader and the face unlock system. If these device designers have no problem throwing a huge amount of money at multiple camera lenses, which you might not even use every day, then they should be fine throwing a ton of money at the biometrics system, which the average user activates dozens of times a day.</p>
<p>I also don't understand why Google is building a face unlock system <em>now</em>. A major downside to a good face unlock system is the multitude of components that need front bezel real estate. The alternative, an in-display (or even rear-mounted) fingerprint reader, requires zero bezel space, allowing more of the front of the phone to be devoted to useful pixels. What, exactly, is the justification for even beginning to build a face unlock system? Even if the Pixel 4's face unlock was as fast and easy as a fingerprint reader (which it isn't), it would still be an inferior option since a fingerprint reader can quickly and easily unlock the phone while using zero bezel space. What are we even <em>aspiring</em> to accomplish here?</p>
<div><a name='page-3'></a></div>
<h3>Motion Sense with Project Soli—Not at all what was promised</h3>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/17-980x550.jpg" alt=""></div>
        <p>
          The original Soli gestures from 2015. None of these work on the Pixel 4.                       [credit:
                        <a href="https://www.youtube.com/watch?v=7GJo_kPLCTQ">Google</a>
                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<p>Google first unveiled Project Soli, a radar-based air gesture system, at Google I/O 2015. The project has been in development at Google's ATAP (Advanced Technology and Projects) group since at least a year before the unveiling, making it five years old now. Project Soli was originally pitched as an <a href="https://youtu.be/7GJo_kPLCTQ?t=116">input solution for smartwatches</a> and other wearables, which have displays small enough that many standard smartphone touch interactions don't translate well. Soli, in the original sales pitch, was a sensor that could capture "sub millimeter motions of your fingers," and Google had developed a number of gestures that could control a smartwatch interface. You could rub two fingers together to spin a virtual dial, tap your thumb and forefinger together to click a button, or scroll through a virtual plane by making a loose fist and sliding your thumb across your forefinger.</p>
<p>After at least five years of development, Project Soli has finally made it to market. Google put its smartwatch navigation solution in ... a smart <em>phone</em> (??), and the feature has been rebranded on the Pixel 4 as "Motion Sense." Immediately, we've lost the initial target. Project Soli was always meant for devices that are too small to house a sizable touchscreen, as the whole goal was bringing some common interface gestures to wearable devices. In a smartphone, which has the sizable touchscreen Soli is trying to replace, Soli makes zero sense.</p>
<p>Even if Soli worked as well as originally advertised, it would have a tough time competing with the ~6-inch touchscreen in the Pixel 4, which gives more direct and immediate feedback than an air gesture. The Pixel 4 doesn't even have the Soli gestures that were originally promised, though. <a href="https://youtu.be/XKmsYB54zBk?t=2231">During</a> the Pixel 4 presentation, Google demoed the Project Soli designs that were shown off in 2015 and 2016, and despite those being pitched as for a smartwatch at the time, Google said it "still wasn't small enough" to fit in a Pixel 4. The company had to "shrink [Soli] down even more." It seems like, in this need to make the chip ever smaller, a lot of the resolution and functionality of Project Soli was compromised.</p>
<p>Instead of the collection of gestures that were originally shown off, Pixel 4 has one control gesture for Project Soli, a horizontal swipe, where you pass your entire hand over the smartphone from left to right or right to left. Soli is very picky about recognizing this gesture, too. You need to make a big arm movement all the way across the entire phone body for it to register—don't use your wrist, use your elbow. In the move to consumerization, Soli has gone from detecting "sub millimeter motions of your fingers" to "elbow-actuated arm waving."</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/23.jpg"><img alt='The Motion Sense, aka Project Soli, options.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/23-980x857.jpg" alt='The Motion Sense, aka Project Soli, options.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/23.jpg"class="caption-link" rel="nofollow">The Motion Sense, aka Project Soli, options.</a> (credit: Ron Amadeo)</p></div>
<p>It's clear that shrinking the Soli chip down made Google move from detecting finger movements to elbow movements. The original Project Soli smartwatch chip, which was shown off at Google I/O 2015, used six radar antennas. Two would transmit a broad beam of radar to your hand, and four antennas would capture the reflected radar as your hand moved around. The Pixel 4 implementation only has four antennas, arranged in a 3+1 configuration. If this follows the same distribution of antennas as the 2015 chip, then one antenna transmits the radar to your hand, and three antennas pick up the reflected signal, a clear loss of resolution. The original Soli chip put its two transmit antennas on opposite ends of the chip, almost as if it wanted to get stereo radar coverage of the object in front of it. With only one transmit antenna, we would be down to a much simpler form of tracking.</p>
<p>So we're down to only one gesture, the horizontal swipe, and with this wave gesture you can navigate "next" or "previous" in a music player, silence alarms, or answer calls. That's about it. The one nice thing about the music implementation is that the Soli sensor works even if the music app is not in the foreground, so you can change tracks, whenever, with a hand wave. This is also something you can do with nearly any pair of Bluetooth headphones, though, so it's not exactly revolutionary.</p>
<p>Motion Sense on the Pixel 4 is not open to app developers, and Google has <a href="https://www.androidpolice.com/2019/10/29/google-has-no-immediate-plans-to-open-motion-sense-api-to-third-party-devs/">no plans</a> to create an SDK in the near future. Google did allow two companies to make short tech demos for Motion Sense, though. One game, <em>Pokémon</em><em> Wave Hello </em>(like it says on the tin),<em> </em>uses the horizontal swipe to allow you to "wave hello" to various Pokémon. Another, <em>Headed South,</em> just uses the horizontal swipe as a replacement for a button—it activates a speed boost in an on-rails flying game. <em>Pokémon</em> uncovers one more extremely limited gesture: a "reach in" gesture where you just block the sensor with your hand for a few seconds. Neither of these apps are things you'd want to play for more than a few minutes.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/10/Pixel-4-10.jpg"><img alt='Hey you, Pikachu. Respond to my frantic flailing.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/10/Pixel-4-10-980x735.jpg" alt='Hey you, Pikachu. Respond to my frantic flailing.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/10/Pixel-4-10.jpg"class="caption-link" rel="nofollow">Hey you, Pikachu. Respond to my frantic flailing.</a> (credit: Ron Amadeo)</p></div>
<p>If it's not clear by now, even these very limited gestures for Project Soli feel terrible. The sensor only notices my arm waving about 75% of the time, and that's just an unacceptable failure rate for an input device. No one would use a mouse, touchscreen, or keyboard that worked 75% of the time (well, <a href="https://arstechnica.com/gadgets/2019/03/apple-apologizes-for-failing-macbook-keyboards-yet-again/">maybe Macbook users</a>), especially when you have a giant 6-inch touchscreen in front of you that can accomplish the same task more accurately and with less effort. Soli might have had a shot when it was attempting "sub millimeter motions of your fingers," but waving your entire arm across the body of the phone is a hassle when a much smaller touchscreen input would accomplish the same thing. The Pixel 4's use of Soli reminds me of the Nintendo Wii and how bad games would use the system's motion controls. Why would users want to make this big arm motion when a simple button press would accomplish the same thing?</p>
<p>Besides the one active gesture, Soli is on all the time and provides "presence detection," which is used for a few things. If an alarm is going off and the Soli sensor detects movement, the alarm volume will lower. Soli can turn on the display when it detects someone, or if you don't want the low-power display mode to be on all the time, it can trigger it when someone approaches. Soli is also tied to the face unlock sensors, which can get a jump on starting up when motion is detected. It would be nice if the Pixel 4 could do something like detect when you are looking at it on a table, turn on the display, and activate face unlock. However, the range of Soli is only about 7 inches, so triggering any of these presence features means sticking a hand out over top of the sensor. You can kind of feel the beginnings of an interesting feature set here, but the range is just too limited.</p>
<p>As a device that broadcasts radar, Soli has to comply with local regulations, and it's not allowed to be used worldwide. A <a href="https://support.google.com/pixelphone/answer/9517454">Google support page</a> lists the countries where the Soli sensor has approval: "Currently, Motion Sense will work in the US, Canada, Singapore, Australia, Taiwan, and most European countries." Soli usage is based on your current location, not where you bought the phone. Google's support page notes that "If you travel to a country where [Motion Sense is] not approved, it won’t work," meaning the feature is geo-fenced based on your current location. In the US, Google has gone back and forth with the FCC about the allowable power levels of Soli, and according to <a href="https://www.reuters.com/article/us-google-sensor/google-wins-u-s-approval-for-radar-based-hand-motion-sensor-idUSKCN1OV1SH">a January report</a> from Reuters, Soli was granted a power level lower than what Google initially wanted. Perhaps this also contributes to the unreliability and limited range of Soli—it's not running at the power level Google initially specced out.</p>
<p>Google says that the current Soli implementation is "just the beginning" and that the company will ship more Pixel 4 functionality "in the coming months." I'm not very optimistic, though, given what we know about the antenna reduction and the poor detection Soli has now. Overall, it feels like a very simple, binary gesture system, like you're just breaking a laser beam with your hand. None of the originally promised Soli functionality seems present here, and I suspect we'll have to see one or two more hardware revisions (hopefully in non-smartphone form factors) before Soli shows any kind of benefit.</p>
<h3>The next-gen Google Assistant</h3>
<p>The software on the Pixel 4 is mostly just stock Android 10, which we have covered to death in our <a href="https://arstechnica.com/gadgets/2019/09/android-10-the-ars-technica-review/">full Android 10 review</a>. There are a few Pixel-specific additions, which mostly boil down to a few packed-in apps. The biggest of those is the new Google Assistant.</p>
<p>The Pixel 4 is the first device that features what Google is calling the "Next Gen Google Assistant." This is a scheme to augment the cloud-based voice recognition system with some local voice processing. This feature was announced at Google I/O 2019, where Google said it created "completely new speech recognition and language understanding models, bringing 100GB of models in the cloud down to less than half a gigabyte." With voice models down to half a gigabyte, they can now be stored locally on the phone, reducing the need for a round-trip to the Internet.</p>
<p>For processing these local voice algorithms, Google has something it calls the "Pixel Neural Core." Is this a chip? Is it a collection of software? Nobody knows! Google published <a href="https://arstechnica.com/gadgets/2017/10/the-pixel-2-contains-a-custom-google-soc-the-pixel-visual-core/">detail specs</a> on the "Pixel Visual Core" for the Pixel 2 and 3, but there has been no such information available for the Pixel Neural Core in the Pixel 4. Google has only ever said "Pixel Neural Core is the engine for on-device processing, always-on computing, and machine learning, meaning more tasks are done on the device for performance and privacy." Note that this does not even identify the Neural Core as a physical chip, only "an engine."</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/30.jpg"><img alt='The new Google Assistant interface has colors fade-in from the bottom of the screen.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/30-980x653.jpg" alt='The new Google Assistant interface has colors fade-in from the bottom of the screen.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/30.jpg"class="caption-link" rel="nofollow">The new Google Assistant interface has colors fade-in from the bottom of the screen.</a> (credit: Ron Amadeo)</p></div>
<p>The Pixel Visual Core in the Pixel 2 and 3 was an extra chip. It was a custom SoC designed by <a href="https://arstechnica.com/gadgets/2017/10/the-pixel-2s-custom-camera-soc-uses-intel-technology/">Intel and Google</a>, with eight Image Processing Units (IPU) capable of more than three trillion operations per second. The Pixel Visual Core was also not used for much. In one of the most Googley hardware decisions ever, Google put a custom camera chip in the Pixel 2 and then <a href="https://www.fonearena.com/blog/235255/in-questions-pixel-camera-qa-with-brian-rakowski-tim-knight.html">did not use it</a> in the Google Camera app. The chip was only used in third-party apps like Snapchat and Instagram. The chip returned in the Pixel 3, where it was <a href="https://ai.googleblog.com/2018/12/top-shot-on-pixel-3.html">only used</a> for the "Top Shot" burst mode feature. Since the Pixel Visual Core was barely used, I could easily see the custom SoC approach getting dumped for the Pixel 4.</p>
<p>iFixit tore down the phone and found two chips that might live under the "Pixel Neural Core" umbrella. There is a <a href="https://www.aisonic.com/wp-content/uploads/2019/10/Knowles-IA8508A-Product-Brief-2019-rev4.pdf">Knowles 8508A</a> quad-core audio processor inside the Pixel 4, which could help with the assistant's voice processing. There's also a mysterious chip with a big "P" on it. Is this the Pixel Neural Core? No one knows, and Google won't provide a clear answer.</p>
<p>Regardless of the actual hardware, is the next-gen Google Assistant a revolution in voice command speed? After all, local processing has to be faster than a round-trip to the Internet, right? After a lot of side-by-side testing, the answer is a resounding "no." I did a lot of queries with the Pixel 4 and the OnePlus 7T side by side, and the two phones traded blows as to which was faster, with neither ever winning by a huge margin. It turns out, when you have a decent connection, a round-trip to the Internet is not all that expensive. You can ping Google.com from just about any command line and see for yourself: you'll get a time back that should be around tens of milliseconds—a time scale you definitely will not notice in real life.</p>
<p>There is a potential for the next-gen Assistant to work without Internet access, but what would you want it to do? Nearly any query you send to the Assistant is going to require network access at some point, unless you want to see some extremely simple, locally stored information like the time or starting a timer. Everything else—texting someone, controlling a smart home, getting a weather forecast, streaming some music—will require the Internet. I would make this same argument against local voice processing providing any sort of privacy benefit—just about everything is an Internet query anyway, so the data will end up on Google servers regardless.</p>
<p>The one real advantage the Pixel 4's Assistant has is that it brings "Continued Conversation" to smartphones. You have to enable this in the settings, but continued conversation means the phone will continue listening for a short time after you issue a voice command. This allows you to issue follow-up commands, which work well thanks to the Google Assistant's contextually aware voice input. Once you ask something like "what's the weather today?" you can ask a follow-up question like "How about tomorrow?" Despite that second command not mentioning "weather," the Google Assistant is smart enough to figure out the context and show you a forecast.</p>
<p>As someone who is all-in on Google's voice command system, I almost never issue a voice command to my phone. When you start a "Hey Google" command, any Google Home speakers in earshot take priority over phones for processing and responding to voice commands, so I've yet to naturally trigger the Pixel 4's "next-gen" Google Assistant. If you're invested in Google's ecosystem, smartphone voice commands are only really useful away from home. And since I would never issue a voice command out in public, I guess that only leaves my car or a friend's house. <em>If</em> the "next-gen" Google Assistant was a tangible upgrade (which it isn't), truly upgrading my Google Assistant experience would mean upgrading the speakers, not my phone.</p>
<div><a name='page-4'></a></div>
<h2>Camera—Pretty much the same as the Pixel 3</h2>
<p>The camera has always been the strength of the Pixel line, although here, again, it seems like Google software prowess is making up for limited hardware. First, Google is using the same sensor as the Pixel 3 (and budget Pixel 3a) for the main camera, the Sony IMX363. There are much bigger and better sensors out there, like the Sony IMX600 used in the latest Huawei devices. The IMX600 has a 1/1.54-inch-type sensor, which has twice the area of the 1/2.55-inch-type sensor used in the Pixel 3 and 4. Google, of course, has better software processing than Huawei, and it can squeeze every drop of image quality out of its old, tiny sensor. But if Google wanted to build the best smartphone camera possible, there is much better hardware out there it could start with.</p>
<p>This year, the Pixel 4 is jumping on the multi-camera bandwagon, but only with a second additional camera. In addition to the 12.2MP main camera, there's now a 16MP 2x telephoto lens. Again if we're comparing this to the best smartphone camera technology out there—which is supposed to be the main draw of the Pixel line, remember—this isn't the best the industry has to offer. Today, 3x telephoto lenses are becoming the norm on devices like the OnePlus 7 Pro, and Huawei and Oppo have been doing amazing things with periscope camera lenses, which turn the whole optical zoom assembly sideways. The Huawei P30 has a 5x optical zoom, and Oppo has a 10x optical zoom prototype, all in a normal-size phone body.</p>
<p>Most multi-camera phones at this price point come with three rear cameras, not just two, and compared to the competition, Google is missing a wide-angle lens. Opting for the telephoto over a wide angle is a bit strange, given that the Pixel 3 already had a "super res zoom" feature, which gave the phone a pretty great AI-assisted digital zoom feature. This feature is a bit better with optical zoom now, but I didn't think improving this was a pressing need.</p>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/IMG_20191103_230003-980x735.jpg" alt=""></div>
        <p>
          Astrophotography mode. Just look at those stars. Note that the sky gets denoised, but not the building.                   </p>
        </div>
      </li>
      </ul>
  

<p>Since the Pixel camera is all about software algorithms, let's talk about the new software algorithm: astrophotography mode. Taking pictures of the stars is actually pretty difficult. It's nighttime, so there's not that much light, so you'll need a long exposure. You can stick your camera on a tripod to stop your camera movement relative to the Earth, but there's nothing you can do to stop the Earth from moving. So even with an exposure of only a few seconds, you'll still get a blurry image. Real astrophotographers get around this by using a "<a href="https://improvephotography.com/50390/using-tracking-mount-landscape-astrophotography/">tracking mount</a>"—a motorized, rotating tripod that compensates for the movement of the Earth.</p>
<p>The Pixel 4's Astrophotography mode does star trail cleanup in software. You stick your phone on a tripod, point it at the night sky, and press the shutter button. The Pixel 4 will then happily sit there for up to four minutes, sucking in as much light as possible, and eventually it will spit out a finished image. Under the hood the phone is taking up to 15 photos with exposures of 16 seconds each, and these then get aligned and merged into a single image, compensating for the movement of the stars, trees swaying in the wind, or any other movement. The pictures the Pixel spits out aren't perfect, but they are far beyond what any other smartphone can muster. If you don't have the special astrophotography tripod gear, the Pixel 4 is far beyond whatever your fancy DSLR can put out, too.</p>
<p>The tough thing about astrophotography on the Pixel 4 (and I guess, in general) is that the viewfinder is basically useless. On the Pixel 4, the viewfinder is usually a black, featureless mess, and it's only after 4 minutes of exposure time that you will have any idea what your lighting and composition looks like. Naturally you want to do this in the darkest place possible, and there were a few times I aimed the camera, took a picture, and four minutes later realized there were trees in the way. It will usually take two or three photos, at 4 minutes each, to get something close to the photo you want. It's a surprise every time.</p>
<p>The other annoying thing about astrophotography mode is that you can't actively enter it. You just turn on night mode, point the camera at the sky for a few seconds, and hope the "Astrophotography on" message pops up. You have to do this for every single photo. Sometimes this works OK, and other times you'll take a night sight photo or two before astrophotography mode kicks on. It depends on the lighting.</p>
<p>Is it too much to ask for this to be a user-selectable mode? The sad thing is that automatic selection limits the other possible creative uses for this long-exposure mode. Some people have managed to get astrophotography mode to take <a href="https://9to5google.com/2019/11/06/pixel-4-light-trails-astrophotography/">sweet light trail images</a>, but getting the camera to do this requires "tricking" it into astrophotography mode. That's an unnecessary hassle.</p>
<p>If you sincerely like astrophotography mode, know that it is also coming to older Pixel phones, including the much cheaper Pixel 3a.</p>
<p>As for the normal camera, I don't think much has changed. In testing, the Pixel 4 traded blows with the Pixel 3, which makes sense given that they have the same sensor. The Pixel 4 camera is still one of the best smartphone cameras, but the lack of improvement is disappointing. Google is just standing still when it comes to basic picture quality.</p>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/pixel4-10-980x735.jpg" alt=""></div>
        <p>
          This fountain can be our zoom subject. Here's the Pixel 4's main camera, so a 1x optical zoom.                   </p>
        </div>
      </li>
      </ul>
  

      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/pixel4-3-980x735.jpg" alt=""></div>
        <p>
          A low-light Pixel 4 shot.                  </p>
        </div>
      </li>
      </ul>
  

      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/pixel-4-e1573250790111-980x1307.jpg" alt=""></div>
        <p>
          The Pixel 4 takes a picture of some alcohol.                   </p>
        </div>
      </li>
      </ul>
  

<h2>What is the point of the Pixel line?</h2>
<p>Google's Pixel line is starting on its fourth year now, and I think it's time we stop treating the smartphone line as a work-in-progress and start asking "What, exactly, is the point of all this?"</p>
<p>When the original Google Pixel first came out, there was an abundance of things you could give Google's new smartphone division the benefit of the doubt on. The design was a year or two behind the competition, with thicker bezels and a less appealing design. Availability was very poor, as the phone was only sold in a handful of countries compared to the world-dominating distribution networks of Apple and Samsung. At a whopping $650, the original Pixel phone was shockingly expensive compared to the awesome value previously provided by the Nexus line. The fabled integration of hardware and software hadn't shown many benefits yet, but that was easy to excuse since the original Pixel was <a href="https://arstechnica.com/gadgets/2016/10/the-google-pixel-a-nine-month-dash-to-mold-an-htc-phone-into-a-google-product/">rushed out the door.</a> "This will all get better," we all thought. Google was just getting started!</p>
<p>We're on generation 4 of the Pixel line now, and nothing has really gotten better. The Pixel 4 design is still dated compared to the competition, sporting a sizable bezel when most of the smartphone world has moved on to <a href="https://arstechnica.com/gadgets/2019/04/galaxy-s10-review-for-1000-samsung-needs-to-offer-a-more-complete-package/" target="_blank" rel="noopener">minimal cameral blemishes</a> or <a href="https://arstechnica.com/gadgets/2019/05/oneplus-7-pro-review-the-fastest-best-designed-best-value-android-phone/" target="_blank" rel="noopener">completely hidden</a> cameras. Distribution is still very bad. The Pixel 4 is only for sale in <a href="https://support.google.com/store/answer/2462844?hl=en">12 countries,</a> a laughable number compared to the <a href="https://9to5mac.com/2017/11/07/iphone-x-countries/">70 countries</a> that Apple does iPhone business in and the <a href="https://news.samsung.com/global/samsung-electronics-officially-launches-galaxy-s10-in-global-markets">100+ countries</a> that can buy the Galaxy S10. The pricing problem has gotten even worse, as the Pixel 4's entry point is now higher than the iPhone 11. Yet, the iPhone 11 has a bigger screen, a bigger battery, and a longer support window.</p>
<p>We're not seeing any benefits from the supposed "deeper" integration of hardware and software, either. In four generations, Google has yet to do anything special with its hardware. It mostly just produces cookie-cutter smartphones at a very high price, doing the same thing as other companies often a year or two behind the competition. Google's few attempts at building something different have all been failures. Google tried building a custom camera co-processor with the Pixel Visual Core, but then it barely used it in its own camera app. The company tried cloning Apple's face unlock system with the Pixel 4, but it built a slow, unreliable system that shipped with security issues other vendors fixed years ago. It tried integrating in-house technology with Project Soli, but that was never meant for smartphones and doesn't work very well anyway. For Google, deeper control over the hardware has mostly just been an avenue to screw up the hardware.</p>
<p>The Pixel's primary software advantage has been day-one updates direct from Google, but even that has become less and less exciting as third-parties get better at shipping updates. OnePlus took <a href="https://arstechnica.com/gadgets/2019/09/the-oneplus-7-pro-gets-android-10-in-just-18-days/">18 days</a> to ship Android 10 to the OnePlus 7 Pro. Google's software updates can still take weeks to fully roll out to the entire population, so it's possible some OnePlus owners received Android 10 before some Pixel owners. Xiaomi and Essential both shipped Android 10 on day one, and let's not forget the 15 third-party OEMs that shipped one or more Android 10 betas this year. Any of the truly useful software creations have been apps like the Google Assistant, which quickly arrive on other phones anyway.</p>
<p>So, what's the point of all this? It's impossible for the Pixel line to be any kind of sales success, because Google just hasn't put in the work to build a world-wide distribution network. It's not pushing the Android ecosystem forward, because the hardware is either the same thing everyone else is doing or it contains a few failed experiments that will be gone in a year or two. There were initial ideas that the Pixel was here to show off Google's software, but when that software boils down to a few apps, you can do that on just about any phone. The Pixel line started off shaky and has been standing still, while Google's competitors get better and better. Today, it doesn't seem like there's much this phone has to offer.</p>
<p>Part of building out the Pixel division included Google <a href="https://arstechnica.com/gadgets/2017/09/googlehtc-deal-is-official-google-to-acquire-part-of-htcs-smartphone-team/">buying a major chunk</a> of HTC's failing phone design division for $1.1 billion. While many people assumed Google would whip this team into shape <a href="https://arstechnica.com/gadgets/2013/08/greater-than-the-sum-of-its-specs-googles-moto-x-reviewed/">like it did</a> <a href="https://arstechnica.com/gadgets/2013/12/review-googles-179-moto-g-puts-every-single-cheap-android-phone-to-shame/">with Motorola</a>, it seems more like the opposite happened. The Pixel hardware has been absolutely HTC-like in its mediocrity. Every year a new piece of "me too" hardware comes out, and every year it feels like something the competition was building one or two years ago. The price is sky high, and this is yet another year of the company standing still when the competition is better than ever. There is not a lot of difference between this Pixel 4 review and a review of something like the <a href="https://arstechnica.com/gadgets/2015/03/htc-one-m9-review-htcs-flagship-feels-like-an-afterthought/">HTC One M9</a>. This unambitious strategy of "just existing" hasn't worked well for HTC, which—we'll forgive you if you haven't noticed—left the US market. That company seems like it's just not going to release a high-end smartphone this generation.</p>
<p>Google's strategy is not working either. According to <a href="https://asia.nikkei.com/Spotlight/Tech-scroll-Asia/Google-to-shift-Pixel-smartphone-production-from-China-to-Vietnam">the IDC</a>, Google shipped 4.7 million Pixel phones in 2018, which works out to a whopping 0.3% global market share. Any sales chart would put Google in the "other" category, below just about every other smartphone OEM you can think of. Apple, by the way, sold 217 million iPhones <a href="https://www.statista.com/statistics/276306/global-apple-iphone-sales-since-fiscal-year-2007/">in 2018.</a> Hardware requires a certain level of commitment, but <em>if</em> the Pixel line was one of Google's many software projects, I think we would all be wondering if it would <a href="https://arstechnica.com/series/google-kills-product/">enter the Google Graveyard</a> soon. Google demands hundreds of millions of users for its software projects to survive, but the company seems content to coast along at the bottom of the hardware market with only a tiny fraction of users.</p>
<p>Google's hardware division just seems to lack ambition. There's no ambition to disrupt the competition and produce something truly unique or different. There's no ambition to compete on price or win any sizable amount of market share. Google Hardware's only ambition seems to be "don't rock the boat." All of these competitors outside of Apple are Android partners who also ship Google software, and they're probably not worth angering. For consumers, this strategy doesn't work. The smartphone market is a cutthroat business, and there are so many hyper-aggressive Chinese OEMs out there, ready to slash prices, push spec envelopes, ship crazy and compelling smartphone designs, and do anything to scratch and claw at more market share. Google's hardware division just doesn't seem interested in competing with all that.</p>
<p>This year, the Pixel 4 feels like a bunch of software decisions designed to prop up hardware that has been cost-cut to death. The battery is tiny. The storage is small and slow. There isn't as much RAM as the competition. These problems aren't just spec sheet arcanery, because you'll feel them in the daily usage of the phone. The battery life is bad. The 90Hz mode can't run all the time, and that means the performance isn't great compared to true 90Hz phones. The display doesn't get as bright as it could, presumably because Google is again worried about the battery.</p>
<p>The amount of compromise required by the Pixel 4 is completely unacceptable in this price bracket. If Google is going to charge a top-tier price, it needs to deliver top-tier hardware, and the company just doesn't seem capable of doing that. This is the first Pixel phone I have no interest in using as a daily driver. It feels like Google has been standing still for four years, and as a result the competition has finally passed Google by.</p>
<h3>The Good</h3>
<ul>
<li>The soft touch backs on the white and orange versions are excellent. If we <em>have</em> to make phones out of glass, this treatment is the best on the market.</li>
<li>The camera is still great, and astrophotography is impressive, but you can get all of this on the much cheaper Pixel 3a.</li>
</ul>
<h3>The Bad</h3>
<ul>
<li>The Pixel 4 is already expensive, but starting at 64GB, when other phones start at 128GB, means the Pixel 4 is even more expensive than it seems at first glance.</li>
<li>This "90Hz" phone doesn't want to run at 90Hz most of the time.</li>
<li>The battery is too small.</li>
<li>No Wi-Fi 6 support. No 4K 60FPS video support.</li>
<li>The tiny base storage and removal of free online storage seem designed to push people toward paying for cloud storage.</li>
<li>Motion Sense doesn't work well, and I'm not sure air gestures are even a good idea on a smartphone to begin with.</li>
</ul>
<h3>The Ugly</h3>
<ul>
<li>Unlocking a phone is the most frequently used action on a device, and face unlock on the Pixel 4 is just slow, frustrating, and inconsistent.</li>
</ul>

<p><a href="https://arstechnica.com/?p=1589011&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Unrelenting “ad blocker” plasters users with—you guessed it—ads</title>
		<link>https://arstechnica.com/?p=1602887</link>
		<pubDate>Sun, 17 Nov 2019 14:00:28 +0000</pubDate>
		<dc:creator><![CDATA[Dan Goodin]]></dc:creator>
				<category><![CDATA[Biz & IT]]></category>
		<category><![CDATA[ad blockers]]></category>
		<category><![CDATA[ad ware]]></category>
		<category><![CDATA[android]]></category>
		<category><![CDATA[apps]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602887</guid>
		<description><![CDATA[Ads Blocker uses several tricks to covertly and constantly bombard users with ads.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/ads-collage-800x500.jpg" alt="Unrelenting “ad blocker” plasters users with—you guessed it—ads"/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/ads-collage.jpg" class="enlarge-link" data-height="563" data-width="900">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="https://www.flickr.com/photos/27845211@N02/2616906744">captcreate / Flickr</a>)</p>  </figure>






<div><a name='page-1'></a></div>
<p>A fake ad blocker available outside of Google Play is bombarding Android users with ads, many of them vulgar, and to make matters worse, the cleverly hidden adware is hard to uninstall.</p>
<p>As <a href="https://blog.malwarebytes.com/android/2019/11/stealthy-new-android-malware-poses-as-ad-blocker-serves-up-ads-instead/">documented by antimalware provider Malwarebytes</a>, Ads Blocker, as the app is called, employs several tricks to surreptitiously and constantly bombard users with ads. The first is to simply ask for usage rights to display over other apps. Next, it makes a connection request to "set up a VPN connection that allows it to monitor network traffic." Finally, it seeks permission to add a widget to the homescreen.</p>
<p>In fact, approving the VPN connection—a standard requirement for some legitimate ad blockers—allows Ads Blocker to run in the background at all times. Combined with the permission to display over other apps, the app is free to plaster ads in a variety of aggressive and annoying ways. It displays full-page ads across the screen. It delivers ads in the default browser. It includes ads in notifications. And it places ads in the homescreen widget.</p>
<p><div class="image shortcode-img right medium"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/missing-icon.png"><img alt='There&#039;s no Ads Blocker icon.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/missing-icon-300x533.png" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/missing-icon.png 2x" alt='There&#039;s no Ads Blocker icon.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/missing-icon.png"class="caption-link" rel="nofollow">There's no Ads Blocker icon.</a> </p></div>"This Android malware is absolutely relentless in its ad-serving capabilities and frequency," Malwarebytes researcher Nathan Collier wrote. "As a matter of fact, while writing this blog, it served up numerous ads on my test device at a frequency of about once every couple minutes."</p>
<p>The content of the ads is wide-ranging, including some, Collier wrote, that are "unsavory" or even "vulgar."</p>
<p>Equally annoying is the difficulty in removing the fake ad blocker from devices. Ads Blocker has no icon. There's no mention of Ads Blocker on the App info section of the Android settings, because the app shields the name with a white box. The concealment leaves many people struggling to uninstall the app. Another white box appears over the notification box. Pressing the box causes a dialog box to appear asking for permission to install yet more apps.</p>
<p><div class="image shortcode-img right medium"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/app-info.png"><img alt='The name of the fake ad blocker is removed from Android&#039;s App Info section.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/app-info-300x533.png" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/app-info.png 2x" alt='The name of the fake ad blocker is removed from Android&#039;s App Info section.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/app-info.png"class="caption-link" rel="nofollow">The name of the fake ad blocker is removed from Android's App Info section.</a> (credit: Malwarebytes)</p></div>Collier went on to describe a simple way to remove the app—by looking for an entry with storage size of 6.57 megabytes in the App Info section of the Android settings. Users can then select that entry and use the uninstall button.</p>
<p>This method didn't appear to work on Android 10, since the App Info box doesn't display storage sizes (at least not on the device I was using). An alternate method in that case may be accessing Storage in the Android settings and choosing the Apps tab. While the Ads Blocker name and icon won't appear, its use of 6.57MB should still be displayed. Users can then press the 6.57MB entry, click the screen immediately above the "clear storage" and "clear cache" icons, and choose uninstall. People can also use the free version of <a href="https://play.google.com/store/apps/details?id=org.malwarebytes.antimalware">Malwarebytes for Android</a> to remove the app.</p>
<p>Malwarebytes researchers still don't know how Ads Blocker is getting distributed. Data in malware-scanning service VirusTotal suggests the app is spreading in the United States, most likely when people look for an ad blocker from a third-party app store. A forum post on a French website and a file name written in the German language provide evidence the app may also be distributed in Europe.</p>
<p>So far, the Malwarebytes app has detected only 500 infections. After collecting more than 1,800 samples of the app, company researchers suspect the total number of infections is much higher.</p>

<p><a href="https://arstechnica.com/?p=1602887&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Microsoft sends a new kind of AI processor into the cloud</title>
		<link>https://arstechnica.com/?p=1602809</link>
		<pubDate>Sun, 17 Nov 2019 12:05:43 +0000</pubDate>
		<dc:creator><![CDATA[WIRED]]></dc:creator>
				<category><![CDATA[Biz & IT]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[cloud]]></category>
		<category><![CDATA[microsoft]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602809</guid>
		<description><![CDATA[Innovative chip from Graphcore could push AI applications to greater heights.
]]></description>
				<content:encoded><![CDATA[





<div><a name='page-1'></a></div>
<p>Microsoft rose to dominance during the '80s and '90s thanks to the success of its Windows operating system running on Intel’s processors, a cosy relationship nicknamed “<a href="https://en.wikipedia.org/wiki/Wintel">Wintel</a>”.</p>
<p>Now Microsoft hopes that another another hardware–software combo will help it recapture that success—and catch rivals Amazon and Google in the race to provide cutting-edge artificial intelligence through the cloud.</p>
<p>Microsoft hopes to extend the popularity of its <a href="https://azure.microsoft.com/en-us/">Azure cloud platform</a> with a new kind of computer chip designed for the age of AI. Starting today, Microsoft is providing Azure customers with access to chips made by the British startup <a href="https://www.graphcore.ai/">Graphcore</a>.</p>
<p>Graphcore, founded in Bristol, UK, in 2016, has attracted considerable attention among AI researchers—and several hundred million dollars in investment—on the promise that its chips will accelerate the computations required to make AI work. Until now it has not made the chips publicly available or shown the results of trials involving early testers.</p>
<p><div class="image shortcode-img right medium"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/02/wired-logo.png"></div>Microsoft, which put its own money into Graphcore last December as part of a $200 million funding round, is keen to find hardware that will make its cloud services more attractive to the growing number of customers for AI applications.</p>
<p>Unlike most chips used for AI, Graphcore’s processors were designed from scratch to support the calculations that help machines to <a href="https://www.wired.com/story/facial-recognition-everywhere-should-you-worry/">recognize faces</a>, <a href="https://www.wired.com/story/google-made-truly-usable-voice-assistant/">understand speech</a>, <a href="https://www.wired.com/story/computers-are-learning-to-read-but-theyre-still-not-so-smart/">parse language</a>, <a href="https://www.wired.com/story/future-of-transportation-self-driving-cars-reality-check/">drive cars</a>, and <a href="https://www.wired.com/story/dont-just-lecture-robotsmake-them-learn/">train robots</a>. Graphcore expects it will appeal to companies running business-critical operations on AI, such as self-driving-car startups, trading firms, and operations that process large quantities of video and audio. Those working on next-generation AI algorithms may also be keen to explore the platform’s advantages.</p>
<p>Microsoft and Graphcore today published benchmarks that suggest the chip matches or exceeds the performance of the top AI chips from Nvidia and Google using algorithms written for those rival platforms. Code written specifically for Graphcore’s hardware may be even more efficient.</p>
<p>The companies claim that certain image-processing tasks work many times faster on Graphcore’s chips, for example, than on its rivals using existing code. They also say they were able to train a popular AI model for language processing, called BERT, at rates matching those of any other existing hardware.</p>
<p>BERT has become hugely important for AI applications involving language. Google <a href="https://www.wired.com/story/google-search-advancing-grade-reading/">recently said</a> that it is using BERT to power its core search business. Microsoft says it is now using Graphcore’s chips for internal AI research projects involving natural language processing.</p>
<p><a href="http://www.moorinsightsstrategy.com/karl-freund-biography/">Karl Freund</a>, who tracks the AI chip market at Moor Insights, says the results show the chip is cutting-edge but still flexible. A highly-specialized chip could outperform one from Nvidia or Google but would not be programmable enough for engineers to develop new applications. “They’ve done a good job making it programmable, he says. “Good performance in both training and inference is something they've always said they would do, but it is really, really hard.”</p>
<p>Freund adds that the deal with Microsoft is crucial for Graphcore’s business, because it provides an on-ramp for customers to try the new hardware. The chip may well be superior to existing hardware for some applications, but it takes a lot of effort to redevelop AI code for a new platform. With a couple of exceptions, Freund says, the chip’s benchmarks are not eye-popping enough to lure companies and researchers away from the hardware and software they are already comfortable using.</p>
<p>Graphcore has created a software framework called Poplar, which allows existing AI programs to be ported to its hardware. Plenty of existing algorithms may still be better-suited to software that runs on top of rival hardware, though. Google’s <a href="https://www.tensorflow.org/">Tensorflow</a> AI software framework has become the de facto standard for AI programs in recent years, and it was written specifically for Nvidia and Google chips. Nvidia is also expected to release a new AI chip next year, which is likely to have better performance.</p>
<div class="image shortcode-img center medium"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/graphcore-2.jpg"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/graphcore-2-300x205.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/graphcore-2-640x437.jpg 2x"></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/graphcore-2.jpg"class="caption-link" rel="nofollow"></a> (credit: Graphcore)</p></div>
<p>Nigel Toon, cofounder and CEO of Graphcore, says the companies began working together a year after his company’s launch, through Microsoft Research Cambridge in the UK. His company’s chips are especially well-suited to tasks that involve very large AI models or temporal data, he says. One customer in finance supposedly saw a 26-fold performance boost in an algorithm used to analyze market data thanks to Graphcore’s hardware.</p>
<p>A handful of other, smaller companies also announced today that they are working with Graphcore chips through Azure. This includes <a href="https://www.citadel.com/">Citadel</a>, which will use the chips to analyze financial data, and <a href="https://www.qwant.com/?l=en">Qwant</a>, a European search engine that wants the hardware to run an image-recognition algorithm known as ResNext.</p>
<p>The AI boom has already shaken up the market for computer chips in recent years. The best algorithms perform parallel mathematical computations, which can be done more effectively on a graphics chips (or GPUs) that have hundreds of simple processing cores as opposed to conventional chips (CPUs) that have a few complex processing cores.</p>
<p>The GPU-maker Nvidia has ridden the AI wave to riches, and Google announced in 2017 that it would <a href="https://www.wired.com/2017/05/google-rattles-tech-world-new-ai-chip/">develop its own chip,</a> the Tensor Processing Unit, which is architecturally similar to a GPU but optimized for Tensorflow.</p>
<p>Graphcore’s chips, which it calls intelligence processing units (IPUs), have many more cores than GPUs or TPUs. They also feature memory on the chip itself, which removes a bottleneck that comes with moving data onto a chip for processing and off again.</p>
<p>Facebook is also working on its own AI chips. Microsoft has <a href="https://www.wired.com/story/microsoft-charts-its-own-path-on-artificial-intelligence/">previously touted</a> reconfigurable chips made by Intel and customized by its engineers for AI applications. A year ago, Amazon revealed it was also <a href="https://www.wired.com/story/new-amazon-chips-cloud-computing/">getting into chipmaking</a>, but with a more general-purpose processor optimized for Amazon’s cloud services.</p>
<p>More recently, the AI boom has sparked a flurry of startup hardware companies to develop more specialized chips. Some of these are optimized for specific applications such as autonomous driving or surveillance cameras. Graphcore and a few others offer much more flexible chips, which are crucial for developing AI applications but also much more challenging to produce. The company’s last investment round gave the company a valuation of $1.7 billion.</p>
<p>Graphcore’s chips might first find traction with top AI experts who are able to write the code needed to exploit their benefits. Several prominent AI researchers have invested in Graphcore, including Demis Hassabis, cofounder of DeepMind, <a href="http://mlg.eng.cam.ac.uk/zoubin/">Zoubin Ghahramani</a>, a professor at the University of Cambridge and the head of Uber’s AI lab, and Peiter Abbeel, a professor at UC Berkeley who specializes in AI and robotics. In <a href="https://www.wired.com/story/googles-ai-guru-computers-think-more-like-brains/">an interview with WIRED</a>last December, AI visionary Geoffrey Hinton discussed the potential for Graphcore chips to advance fundamental research.</p>
<p>Before long, companies may be tempted to try out the latest thing, too. As Graphcore’s CEO Toon says, “Everybody's trying to innovate, trying to find an advantage.”</p>
<p><em>This story originally appeared on <a href="https://www.wired.com/story/microsoft-sends-a-new-kind-of-ai-processor-into-the-cloud/">wired.com</a>.</em></p>

<p><a href="https://arstechnica.com/?p=1602809&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Frank Miller inks deal for a Sin City TV series based on his neo-noir comics</title>
		<link>https://arstechnica.com/?p=1602913</link>
		<pubDate>Sat, 16 Nov 2019 18:42:48 +0000</pubDate>
		<dc:creator><![CDATA[Jennifer Ouellette]]></dc:creator>
				<category><![CDATA[Gaming & Culture]]></category>
		<category><![CDATA[Dark Horse Comics]]></category>
		<category><![CDATA[entertainment]]></category>
		<category><![CDATA[Frank Miller]]></category>
		<category><![CDATA[Sin City]]></category>
		<category><![CDATA[television]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602913</guid>
		<description><![CDATA[Robert Rodriguez, who directed the two <em>Sin City</em> films, could sign on to project, too.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/cityTOP-800x523.jpg" alt="Mickey Rourke played tough guy Marv in the 2005 film, <em>Sin City</em>, and its 2014 sequel, <em>Sin City: A Dame to Kill For.</em>"/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/cityTOP.jpg" class="enlarge-link" data-height="785" data-width="1200">Enlarge</a> <span class="sep">/</span> Mickey Rourke played tough guy Marv in the 2005 film, <em>Sin City</em>, and its 2014 sequel, <em>Sin City: A Dame to Kill For.</em> (credit: YouTube/Miramax)</p>  </figure>






<div><a name='page-1'></a></div>
<p>We're getting a TV adaptation of <em>Sin City</em>, Frank Miller's series of <a href="https://en.wikipedia.org/wiki/Sin_City">neo-noir comics</a> inspired by crime pulp fiction, <a href="https://deadline.com/2019/11/sin-city-tv-series-frank-miller-robert-rodriguez-legendary-television-1202787314/">Deadline Hollywood reports</a>. Miller just inked a deal with Legendary Television for the project, and apparently a similar agreement is close to completion with Robert Rodriguez, who collaborated with Miller on the film adaptions of the comic series in 2005 and 2014. The agreement comes with a first season guarantee, pending a partnership with one of the major networks or streaming platforms. Given that Miller wants the series to rate a hard "R," streaming seems the most likely option.</p>
<p>Miller cut his teeth in the 1980s on Marvel Comics' <em>Daredevil</em> series and DC Comics' <em>The Dark Knight Returns</em>. A longtime fan of film noir, especially the films of James Cagney and Humphrey Bogart, Miller wanted to bring that same tone to <em>Sin City</em>, an anthology of stories set in the fictional Western town of Basin City (aka Sin City). The series art was noteworthy for its unique aesthetic, drawn almost entirely in black and white, with occasional bright splashes of color (red, yellow, blue, or pink) to highlight certain characters. And Miller drew on classic pulp fiction for the writing as well.</p>
<p>Almost every inhabitant of Sin City is corrupt, from the police department to the wealthy Roark family dynasty, with different factions carving out niches in the overall hierarchy. Miller <a href="https://www.youtube.com/watch?v=Xo7frKC0N2E&amp;t=2431s">has said</a> he wanted it to be "a world out of balance, where virtue is defined by individuals in difficult situations, not by an overwhelming sense of goodness that was somehow governed by this godlike <a href="https://en.wikipedia.org/wiki/Comics_Code_Authority">Comics Code</a>." So we get stories, or "yarns," about one man's brutal rampage to avenge his lover's killer; gang wars; and the hunt for a disfigured serial killer targeting young women. The yarns aren't necessarily connected, but they all take place in the same fictional world, and various characters recur in different stories.</p>
<div class="image shortcode-img center large"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/city2.jpg"><img alt='A mesmerizing Eva Green couldn&#039;t save &lt;em&gt;Sin City: A Dame to Kill For&lt;/em&gt; from critical and box office failure.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/city2-640x421.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/city2.jpg 2x" alt='A mesmerizing Eva Green couldn&#039;t save &lt;em&gt;Sin City: A Dame to Kill For&lt;/em&gt; from critical and box office failure.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/city2.jpg"class="caption-link" rel="nofollow">A mesmerizing Eva Green couldn't save <em>Sin City: A Dame to Kill For</em> from critical and box office failure.</a> (credit: Dimension Films)</p></div>
<p>The 2005 film adaptation, <em>Sin City</em>, focused mostly on the first, third, and fourth books in the series (<em>The Hard Goodbye, The Big Fat Kill</em>, and <em>That Yellow Bastard</em>). From the start Rodriguez sought to remain true to the source material; the only writing credit is "based on the graphic novels by Frank Miller." He also brought Miller on board as co-director to ensure the film had the same distinctive look as the comics. Since the Director's Guild of America refused to grant full directing credit to both men because they weren't part of an established team, Rodriguez famously resigned his membership to preserve the dual credit.</p>
<p>That gamble paid off when <em>Sin City</em> premiered in 2005 to critical acclaim and box office success, grossing $158.7 million worldwide. It was a finalist for the prestigious Palme d'Or at the Cannes Film Festival that year, winning the Technical Grand Prize for its striking visual style. Alas, the 2014 sequel, <a href="https://en.wikipedia.org/wiki/Sin_City:_A_Dame_to_Kill_For"><em>Sin City: A Dame to Kill For</em></a>, fizzled at the box office, earning a meager $39.4 million globally against a $65 million production budget. It was largely slammed by critics, too, who found the visuals less striking the second time around and the story slow and repetitive, although the stellar cast received praise.</p>
<p>It's early days yet for the planned TV series' development, so we know very little about the details. But when rumors of a TV adaptation surfaced in 2017, <a href="https://deadline.com/2017/05/frank-miller-sin-city-tv-series-glen-mazzara-len-wiseman-stephen-lheureux-1202104935/">Deadline noted</a>, "The intention is to be a far departure from the films, introducing original characters and timelines within the Sin City universe." Since Rodriguez is likely to be involved again, chances are he'll be looking to tell fresh stories from Miller's comic <em>oeuvre</em>, rather than retreading the same narrative ground of the two film adaptations. Television is a very different medium, arguably better suited than film to Miller's anthology format. Let's hope it preserves that distinctive neo-noir look of the films, at least.</p>

<p><a href="https://arstechnica.com/?p=1602913&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Tapestry: Has the mythical “2-hour civ-building board game” arrived?</title>
		<link>https://arstechnica.com/?p=1602811</link>
		<pubDate>Sat, 16 Nov 2019 16:00:23 +0000</pubDate>
		<dc:creator><![CDATA[Ars Staff]]></dc:creator>
				<category><![CDATA[Gaming & Culture]]></category>
		<category><![CDATA[ars cardboard]]></category>
		<category><![CDATA[Board games]]></category>
		<category><![CDATA[Tapestry]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602811</guid>
		<description><![CDATA[One of the year's most anticipated board games is a 2-hour civ-builder.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/IMG_4459-800x600.jpg" alt="Gettin' ready for some two-hour civ building."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/IMG_4459.jpg" class="enlarge-link" data-height="3000" data-width="4000">Enlarge</a> <span class="sep">/</span> Gettin' ready for some two-hour civ building. (credit: Dan Thurot)</p>  </figure>




      <p><em>Welcome to Ars Cardboard, our weekend look at tabletop games! Check out our complete board gaming coverage at <a href="http://cardboard.arstechnica.com/">cardboard.arstechnica.com</a>.</em></p>
    

<div><a name='page-1'></a></div>
<p>As a longtime player of cardboard civilization games, I’m always looking for titles that break the mold. From the moment it was revealed, Jamey Stegmaier’s <em>Tapestry</em> looked like it might fit the bill. With its pre-painted buildings, non-historical civilizations, and the hieroglyphic script that runs the perimeter of the board, it seemed to promise a civilization game that wasn’t quite like any other.</p>
<p>And, well, it certainly delivers on that front. <em>Tapestry</em> is indeed unlike most of its civ-game peers.</p>
<p>But not everyone loves it. A couple months after its release, the game has proved surprisingly divisive. And there’s a reason for that—it just happens to be more complicated than “this game is good” or “this game is bad.”</p>
<h3>A (non-traditional) civilization game</h3>
<div class="image shortcode-img right medium"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/3d-tapestry.png"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/3d-tapestry-300x352.png" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/3d-tapestry-640x750.png 2x"></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/3d-tapestry.png"class="caption-link" rel="nofollow"></a> (credit: Stonemaier Games)</p></div>
<p>Let’s start with the positive. In a genre packed with over-complicated (and over-long) entries, <em>Tapestry</em> fulfills its promise of a two-hour civilization game with minimal rules. To some extent, the low learning curve is a smokescreen; the rulebook is only four pages long, but it offloads a number of concepts onto a dense double-sided reference sheet. And as anyone who’s shared a table with a friend named Geoff knows all too well, two hours can quickly stretch to three once some decisions need making.</p>
<p>Still, that’s pretty slim. For the most part, <em>Tapestry</em> really is lean. Nearly every turn is neatly handled by pushing yourself up a single space on one of the board’s four advancement tracks. These are the hieroglyphs I mentioned earlier, representing concepts like <em>warfare</em>, <em>exploration</em>, <em>science</em>, and <em>technology</em>, and they’re even more important than the hex-grid map that dominates the board. You pay a resource or three to move into your chosen track’s next space, gain a benefit, and occasionally pay for a bonus. Easy. All the better that these tracks spit out incremental rewards faster than any free-to-play app.</p>

<p>This is also where <em>Tapestry’s</em> non-traditional nature begins to show through, along with some of the issues that have proven disappointing to those who want “theme” in their board games. The advancement tracks exist in isolation, freeing the player to move along any track of their choosing as long as their resources hold out. This can feel liberating when it comes to potential combinations, letting you maximize your returns as often as possible. But there’s really nothing stopping you from developing <em>neuroscience</em> before <em>stone tools</em>, or boarding a space shuttle to distant worlds before figuring out that exploding powder can hurl objects at lethal velocities in an enemy army’s direction.</p>
<p>Is this a problem? It depends on whether you play games to knock systems against each other for points or because those systems support a coherent narrative. One of the hallmarks of the civilization genre has always been the sweeping narratives it produces, often leading to those aforementioned complicated rules.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/IMG_4460.jpg"><img alt='Look at all those pre-painted minis...'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/IMG_4460-980x449.jpg" alt='Look at all those pre-painted minis...' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/IMG_4460.jpg"class="caption-link" rel="nofollow">Look at all those pre-painted minis...</a> (credit: Dan Thurot)</p></div>
<h3>We built this city... on advancement tracks</h3>
<p>If the point hasn’t already been firmly stated, <em>Tapestry</em> avoids this traditional direction. There are tech cards, but they don’t create a “tech tree” like any you’ve scrutinized before. Inventions like eyeglasses and anesthesia are cool to see on the table, and they raise questions over which technologies were crucial to human development. Was the wheel really such a big deal? <em>Tapestry</em> isn’t actually interested in such musing, just as it isn’t interested in explaining why plumbing gives you an armory or why warships dole out extra workers.</p>
<p>Perhaps the most overt indicator of this approach comes in the form of your capital city. As your civilization grows, new buildings are gradually added to your personal board, transforming it from swampland to city. Or, from mountaintop to metropolis. Or, from desert to deserted, if you’re too slow to grab the right landmarks. (Speaking of which, landmarks are awarded for being the first to hit certain spaces on the advancement tracks. Train stations and tank factories, lighthouses and shuttle launch pads—these stand out as a momentous reward for your hustle.)</p>
<p>What do these landmarks do? Fill space. Really, that’s what they do. Don’t get me wrong, filling space in your capital city is an important process. When sectors are completely filled, you get an extra resource. Completed rows and columns, meanwhile, award points. Some gamers are disappointed that an “academy” landmark does nothing more thematic than block off a 4x2 grid. Fair enough. (Although it wouldn’t be the first government project that did little more than clog up some city’s downtown.)</p>
<p>Like everything else in <em>Tapestry</em>, the city building is perfectly functional, if weirdly remote from its subject matter. It’s possible to target landmarks that will propel you ahead of the competition, whether economically or score-wise. Unfortunately, your capital might also resemble a circuit board, a weird latticework settlement that no human mind would ever willingly create or inhabit.</p>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/IMG_1540-e1565357207573-980x980.jpg" alt=""></div>
        <p>
          Cities are certainly colorful.                      [credit:
                        Stonemaier Games                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<h3>Unraveling the tapestry</h3>
<p>At this point it would be easy to argue that <em>Tapestry</em> is mechanically sound but narratively empty. Easy, but an oversimplification.</p>
<p>Both assumptions are undermined by the titular “tapestry” cards. Think of them like a national identity, something that lingers across generations to form the backbone of your culture. Maybe you’ll host the Olympics and bask in their prestige, or marry into another player’s royal family to leech off their advancements, or embrace terraforming to make your capital city look less like a Borg cube. Each player uses just three of these cards over the entire game, and the cards endow each civilization with a sense of identity and history. A diplomatic neighbor can genuinely feel like an old pal, while dictatorial oil barons with a history of pillaging are best avoided. (Bet you didn’t see that one coming.)</p>
<p>But tapestry cards are also wildly divergent in their effects. You’ll draw many more than you can play, but not always in time and not always with options that mesh well with the shape of your civilization. Bad draws alone don’t make the game unwinnable, but <em>Tapestry </em>does seem to set different point ceilings for the cultures clashing at the table. In other words, these cards take a wrench to any easy statements about the game, providing both much-appreciated dashes of narrative spice while also frustrating the best-laid plans.</p>
<p><em>Tapestry</em> is complicated to assess. I'm certain its ideas are clever, even innovative, and it effectively <em>reduces</em> the civilization formula. But that word carries a double meaning. The game is reduced to essentials—a point-chaser that rewards both careful planning and outright chance. But it is also reduced to its bones, stripping away the interactions and narrative that make a two-hour civ-game such a holy grail among board gamers.</p>
<p>The game is divisive, then, and likely to stay that way. I’m glad Stegmaier tried to take the civilization game beyond its comfort zone. Experiments are worthwhile, even when their results are imperfect, and this may be right for you. But when it comes to the reasons I play board games—the interactions between players, the narratives that arise from play, the thematic statements—this <em>Tapestry</em> is bare of the threads I value most.</p>

<p><a href="https://arstechnica.com/?p=1602811&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>The science of audio: How a podcast reveals the pleasant mysteries of hearing</title>
		<link>https://arstechnica.com/?p=1602133</link>
		<pubDate>Sat, 16 Nov 2019 15:00:26 +0000</pubDate>
		<dc:creator><![CDATA[Ars Staff]]></dc:creator>
				<category><![CDATA[Gaming & Culture]]></category>
		<category><![CDATA[ASMR]]></category>
		<category><![CDATA[podcasts]]></category>
		<category><![CDATA[reasonably sound]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602133</guid>
		<description><![CDATA[Plus, chat with series creator on how he began exploring the dulcet tones of science.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/asmr-microphone-800x450.jpg" alt="The science of audio: How a podcast reveals the pleasant mysteries of hearing"/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/asmr-microphone.jpg" class="enlarge-link" data-height="563" data-width="1000">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="https://arstechnica.com/author/aurich-lawson/">Getty Images / Aurich Lawson</a>)</p>  </figure>






<div><a name='page-1'></a></div>
<p>The first episode of audio-obsessed podcast <em>Reasonably Sound</em> that made me stop and think was an early entry called "<a href="http://reasonablysound.com/2014/10/02/whisper-quiet/">Whisper Quiet</a>." As my introduction to Autonomous Sensory Meridian Response (ASMR), and the specific auditory cues related to its reported physical reactions, I felt like someone had taken the top off my head, rummaged around in my brain, and found something overlooked inside that was suddenly useful. And not just in an ASMR sense, though the sample clips of Bob Ross hit all the right notes for that, as did host Mike Rugnetta getting into the spirit of ASMR by whispering the end credits.</p>
<p><a href="http://reasonablysound.com/"><em>Reasonably Sound</em></a> is a podcast about audio and about the historical and cultural context of particular sounds and sonic experiences. In his episode about ASMR, Rugnetta not only introduces his audiences to what ASMR is, but he also contextualizes the rise of ASMR culture on YouTube within the broader history of communication technology, starting with an AT&amp;T advertising campaign from the 1970s promoting long-distance calls as a medium for emotional intimacy. He also digs into the jargon of ASMR culture, comparing the pleasant "triggers" found in ASMR videos to the more serious triggers of trauma responses.</p>
<p><a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=autonomous+sensory+meridian+response">Research into the causes of ASMR</a> didn't start being published in earnest until 2015, months after the release of "Whisper Quiet," so Rugnetta mentions in a later episode that he's skeptical of the phenomenon’s existence. But, real or imagined, he acknowledges <a href="https://www.twitch.tv/directory/game/ASMR">ASMR's memetic status</a> and delights in exploring the cultural context that produced it.</p>
<h2>Do you hear what I hear</h2>
<p>Every episode of <em>Reasonably Sound</em> follows a similar structure before delivering audio-related revelations. Rugnetta starts by focusing on a single sonic concept, then dives into that concept's cultural context. For example, "<a href="http://reasonablysound.com/2014/10/30/taylor-swifts-white-noise/">Taylor Swift's White Noise</a>" begins by explaining how white noise works and goes on to dig into the cultural distinction between noise and music, centered on an incident in 2014 in which Swift accidentally released eight seconds of white noise as a song on iTunes. "<a href="http://reasonablysound.com/2016/12/12/for-whom-the-whistle-blows/">For Whom the Whistle Blows</a>" is about dog whistles, both as literal canine-directed noisemakers and as a political metaphor from the United States' 2016 election season.</p>
<p>And "<a href="http://reasonablysound.com/2015/04/16/mollys-misophonia/">Molly's Misophonia</a>" mirrors "Whisper Quiet" by explaining the opposite of ASMR: a psychiatric condition called misophonia, in which certain sounds, like chewing or paper rustling, are physically unbearable. To complete the reflection, this episode gets personal instead of exploring a broader context.</p>
<p>Rugnetta interviews his partner Molly Templeton about how her misophonia affects her life. Misophonia is triggered not only by sounds, but by sounds in context, and a person's misophonia is most often triggered by their family and close friends. By interviewing Templeton about her experience, Rugnetta learned how the everyday household noises he produces accidentally contribute to her discomfort.</p>
<h2>A reasonable idea about sound</h2>
<p><em>Reasonably Sound</em> grew out of Rugnetta's previous project, a video series for PBS called Idea Channel that ran from 2011 to 2017 and explored pop culture topics in similar depth. The original idea for Idea Channel revolved more around sound and audio, Rugnetta tells Ars Technica, but the scope of the project gradually broadened. The idea for a sound-focused show was shelved until a friend of Rugnetta's at American Public Media invited him to work on his original idea as part of APM's podcast network starting in 2014.</p>
<p>In the mid 2010s, as Rugnetta became busier with other projects, <em>Reasonably Sound</em> became the podcast he worked on for his own edification and peace of mind. He returned to what he'd always seen as the show's goal: to "explore the less obvious ways sound frames and informs the human experience," from sound design in cinema ("<a href="http://reasonablysound.com/2016/11/21/the-braaam/">The BRAAAM™</a>") to the cultural context of applause and booing ("<a href="http://reasonablysound.com/2017/10/20/put-em-together/">Put 'Em Together</a>" and "<a href="http://reasonablysound.com/2017/11/22/boo-who/">Boo Who?</a>") to the public safety hazards of silent electric-car engines ("<a href="http://reasonablysound.com/2019/02/07/vrooms-and-the-lack-thereof/">Vrooms and the Lack Thereof</a>").</p>
<p>While episodes of <em>Reasonably Sound</em> became less frequent as other projects took precedence and the research for <em>Reasonably Sound</em> itself increased in depth and complexity, new episodes remain "a rare treat" for fans. They're released when they're ready and not before; they're full of solid research, reasoning, and sound design; and even the most potentially stressful topics are narrated in Rugnetta's soothing voice.</p>
<p>Rugnetta recommends that new listeners start with his most recent episode and work backward. As of press time, his most recent episode—and the one he's most proud of—is "<a href="http://reasonablysound.com/2019/08/19/the-world-remade/">The World Remade</a>," which explores the environmental impacts of vinyl record production and online music streaming. He also recommends "<a href="http://reasonablysound.com/2018/02/27/helpful-mom-voices/">Helpful Mom Voices</a>," about the history of machines that speak and the cultural reasons why Siri, Cortana, and other digital assistants sound the way they do, as a good example of the perspective the show takes about its subjects.</p>
<p>I come to this review with years of fandom as a bias, I admit, but I'd argue that <em>Reasonably Sound</em> might be <em>the</em> podcast for people who yawn at the concept of podcasts. Its variety of topics, depth of research, and wonderfully pleasant production make it an all-in-one audio destination in which you can plug your ears into every detail of the audio experience.</p>

<p><a href="https://arstechnica.com/?p=1602133&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Dark matter link to regular matter’s dominance fails to show up</title>
		<link>https://arstechnica.com/?p=1602835</link>
		<pubDate>Sat, 16 Nov 2019 13:30:33 +0000</pubDate>
		<dc:creator><![CDATA[John Timmer]]></dc:creator>
				<category><![CDATA[Science]]></category>
		<category><![CDATA[antimatter]]></category>
		<category><![CDATA[axions]]></category>
		<category><![CDATA[Dark Matter]]></category>
		<category><![CDATA[Physics]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602835</guid>
		<description><![CDATA[If axions influence antimatter's behavior, the effects are tiny.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/201803-075_04-800x534.jpg" alt="Image of a high energy physics lab."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/201803-075_04.jpg" class="enlarge-link" data-height="1334" data-width="2000">Enlarge</a> <span class="sep">/</span> Given how messy a typical physics lab is, CERN is just as likely to lose the antimatter it intends to store. (credit: <a rel="nofollow" class="caption-link" href="https://home.cern/news/news/physics/alpha-experiment-takes-antimatter-new-level">Maximilien Brice, Julien Ordan/CERN</a>)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Matter, despite being omnipresent here on Earth, is a bit of a mystery. Most of the matter in the Universe comes in the form of dark matter, which doesn't seem to have significant interactions with light or other matter. Meanwhile, the more familiar form of matter shouldn't be here at all. It should have been created in equal amounts to antimatter, allowing the two to annihilate each other following the Big Bang.</p>
<p>Physicists have found a few ways of breaking the matter/antimatter symmetry, but they aren't sufficient to account for matter's vast predominance. So, there are lots of ideas floating around to handle it, and some of them are even testable. One of the more intriguing categories of solution links the two big problems with matter: tying the prevalence of matter to the existence of a specific dark matter particle.</p>
<p>Now, scientists have made some antimatter in a lab and used that to test one of these ideas. The test came up blank, putting limits on the possible link between dark matter and antimatter's absence.</p>
<h2>Meet the axion</h2>
<p>For many years, research has focused on a class of potential dark matter particles called WIMPs, for weakly interacting massive particles. These heavy, relatively slow-moving particles are the best fits for the properties of dark matter inferred from the behavior of our Universe. But searches for WIMPs—including those conducted at the <a href="https://arstechnica.com/science/2015/04/a-rare-lhc-tour-avoiding-radiation-to-see-scientific-history-up-close/">Large Hadron Collider</a> as well as dedicated detectors—have all failed to find them. This has caused many researchers to start considering alternatives to WIMPs when it comes to dark matter.</p>
<p>One of those alternatives is <a href="https://arstechnica.com/science/2015/01/if-dark-matter-is-really-axions-we-could-find-out-soon/">the axion</a>, a particle first proposed as a way of solving problems in an unrelated area of physics called quantum chromodynamics. Axions would be lighter than WIMPs but still present in large enough numbers to account for dark matter without the need for additional particles. Because their properties have already been defined by their role in quantum chromodynamics, there are a lot of ideas to test for the axion's existence. Some of those tests are currently in progress.</p>

<p>The new study goes well beyond simply testing whether axions exist. Instead, it explores whether they might interact differently with antimatter than with regular matter. Not only would this provide evidence of the axion's existence, but it could hint at why antimatter ended up so rare in our Universe.</p>
<h2>Or rather, fail to meet it</h2>
<p>So how do you go about looking for axion-antimatter interactions? Like regular particles, antimatter particles have a spin that will align with external magnetic fields. Like a top, however, that spin can undergo <a href="https://en.wikipedia.org/wiki/Precession">precession</a>, in which it wobbles around a direct alignment with the magnetic field. If axions exist and interact with antimatter, they should do so in a way that alters this wobbling. And, if axions are dark matter, those interactions should be frequent enough that we should see them.</p>
<p>The big "if" to getting this experience to work is that you not only need to get ahold of some antimatter, but you need to keep it from running into regular matter for long enough to do repeated measurements on its spin. Conveniently, CERN has <a href="https://arstechnica.com/science/2011/06/antimatter-atom-held-trapped-for-15-minutes/">just the ticket</a> for grabbing some antimatter and holding it still.</p>

<p>That allowed them to measure the antimatter's precession, which produced a result that was indistinguishable from what you'd expect if axions didn't exist. That doesn't mean the interaction doesn't take place. It does, however, mean that any interaction that occurs happens with axions that have different properties than the ones assumed in this experiment. By gradually excluding possible axion properties, experiments like this and others could eventually push them out of consideration—for example, if axion masses that would work as dark matter end up being excluded, there's much less point in considering their existence.</p>
<p>Of course, this is only for axions that also happen to interact with antimatter differently from how they interact with regular matter. There's no particular reason to think these exist other than optimism—specifically, optimism that we could tie up two annoying problems in physics at the same time.</p>
<p><em>Nature</em>, 2019. DOI: <a href="http://dx.doi.org/10.1038/s41586-019-1727-9">10.1038/s41586-019-1727-9</a>  (<a href="http://arstechnica.com/science/news/2010/03/dois-and-their-discontents-1.ars">About DOIs</a>).</p>

<p><a href="https://arstechnica.com/?p=1602835&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>The version of Star Wars on Disney+ changes the canon once again</title>
		<link>https://arstechnica.com/?p=1602799</link>
		<pubDate>Sat, 16 Nov 2019 11:38:36 +0000</pubDate>
		<dc:creator><![CDATA[WIRED]]></dc:creator>
				<category><![CDATA[Gaming & Culture]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602799</guid>
		<description><![CDATA[Han Solo vs. Greedo might look different than it did in 1977. And 2004. And 2011.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/han-greedo-800x332.jpg" alt="Who shot first?"/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/han-greedo.jpg" class="enlarge-link" data-height="597" data-width="1440">Enlarge</a> <span class="sep">/</span> Who shot first? (credit: Lucasfilm Ltd. | Disney)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Drew Stewart got the call at around 2am: They broke the universe again, you should check it out.</p>
<p>So Stewart did something he's done countless times before; he has no idea how many. He turned on <em><a href="https://www.wired.com/story/guide-star-wars/">Star Wars</a></em>. But this time was different—literally. The galaxy had changed, like a glitch in the Matrix (if you'll allow a mixed cinematic metaphor). And it wasn't the first time.</p>
<p>As the person behind a Twitter account called <a href="https://twitter.com/starwarsviscomp">Star Wars Visual Comparison</a>, Stewart is a kind of unofficial keeper of apocrypha, of the sometimes subtle, sometimes extraordinary changes wrought by their makers upon three <em>Star Wars</em> movies: <em>A New Hope</em>, <em>The Empire Strikes Back</em>, and <em>The Return of the Jedi</em>. These alterations to the canon are the stuff of many nerd debates, and Stewart has followed them closely. That's why, at 2:50am on the day <a href="https://www.wired.com/story/disney-plus-power-launch/">Disney+</a> launched with the whole <em>Star Wars</em> catalog in 4K resolution (pretty!), he found himself watching <em>A New Hope</em> yet again. What he found was yet another wrinkle: an <a href="https://twitter.com/GarrettMcDowel1/status/1194236198774022144">all-new, all-different shoot-out </a>between Han Solo and the lizardish bounty hunter Greedo.</p>
<p><div class="image shortcode-img right full"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/02/wired-logo.png"></div>Having just spent a week on the changes made to this scene since 1977—when, originally, Han kills Greedo in cold blood in the Mos Eisley cantina—Stewart knew he was seeing something extraordinary. He took to <a href="https://twitter.com/StarWarsVisComp/status/1194160489825284097">Twitter</a> with word of his findings, and you can hear the existential despair in his voice: "Oh my god. This is not a joke."</p>
<p>So what's going on here? Well, the first <em>Star Wars</em> movie came out in 1977. And then things went kind of joojoofloopy. In 1981, Lucasfilm added the title "A New Hope" to the opening crawl, signaling that <em>Star Wars</em> is a genus, not a species. Recreating that crawl necessitated a new starfield behind it, so the giant spacecraft you see in the opening scene had to be recomposited. OK. Then, in 1997, the "special editions" came out with all sorts of new visual effects—new X-wings and a digital Jabba the Hutt in <em>A New Hope</em>, expanding shock wave rings around explosions, stuff like that. And, maybe most controversially, Greedo gets a shot off before Han. "It lasts like 20 frames or something. Greedo shoots, and Han just kind of sits there and then fires back eventually. Twice? He shoots twice. I don't know how they animated that and got it through quality control," Stewart says.</p>
<p>"Then we have the DVD version, which came out in 2004, and it had a myriad of changes," Stewart says—including retiming the shoot-out. "And then the Blu-rays came out in 2011, and there were more things." Like, for example, they cut the pause altogether.</p>
<p>And the version that's on Disney+ now? "It's a whole new thing. I just don't understand," Stewart says. "The insert shot of Greedo? That's just the shot of Greedo from a few seconds before, but zoomed in poorly. Then he says a nonsense word, and then they shoot at the same time. And he explodes." That nonsense word doesn't even get translated in the subtitles. It's something like "<a href="https://www.hollywoodreporter.com/heat-vision/star-wars-fans-confused-by-greedos-added-dialogue-disney-1254141">maclunkey</a>," and it launched memes, as things do now.</p>
<p>As a nerd, even I'll allow this seems like small beer, in a way. <em>Star Wars</em> creator George Lucas tinkered on his stuff for decades before Disney bought his company, nominally locking the prints. One more change shouldn't come as a huge surprise, especially since, as a Lucasfilm spokesperson confirmed, Lucas himself made the changes to the Han/Greedo scene after the Blu-ray release in 2011 and before the Disney acquisition in 2012. For fans, though, it's something that makes the movie one more step removed from what hit theaters 42 years ago.</p>
<h2>From a certain point of view</h2>
<p>Put another way, the Disney+ version of <em>Star Wars</em> means the canon now includes 1977's <em>A New Hope</em> and its 1981 revise, 1980's <em>Empire</em>, and 1983's <em>Jedi</em>. The 1997 special editions, on film and in 2K resolution. The 2004 special editions on DVD, from a 1080p master. The 2011 special editions, again in 1080p, for Blu-ray. And now … this. Which is what, exactly?</p>
<p>Stewart went back to his computer and his TV screen and did a rewatch, and he has some concerns. After we spoke, he DM'd me to say that he thought the Disney+ versions had too many color corrections to merely be a Greedo-tweaked, uprezzed 2011 Blu-ray version. "According to anonymous sources, this is what Lucas worked on after the Blu-ray, a 4K cut with all these changes," Stewart says—an all-new edition made from the original negatives of the 1997 special edition. "It's not a revision," he wrote. "It's a whole new fork."</p>
<p>A Lucasfilm representative sort of denied this. "The 4K are from the Blu-ray releases," the person said.</p>
<p>So I asked: Just to make sure, then, Stewart's guess is wrong? It's not a new fork, the Disney+ movies are revisions of the 2011 releases and not entirely new versions made from the 1997 special edition negatives, with redone visual effects? No response.</p>
<p>This isn't the only weird choice Disney+ made. At the same time as the Greedo thing was unfolding, <em>Simpsons</em> fans were gnashing their terrible teeth and roaring their terrible roars about the decision to show early-days episodes cropped to fit new, hi-def screens instead of presenting them in their original 4:3 standard-def aspect ratio. You lose a lot of visual jokes that way, like (perhaps most famously) learning on a widening shot that the three kinds of Duff beer (Duff, Duff Lite, and Duff Dry) all come from <a href="https://twitter.com/TristanACooper/status/1194298167824650240">the same pipe</a>. The originals are readily available, unlike the earlier rounds of <em>Star Wars</em> revs; FXX showed them. The 4:3 eps just … aren't there.</p>
<h2>Why?</h2>
<p>But why? Why not just load everything onto the servers and let subscribers choose, as a reward for paying to be part of the broader Disney ecosystem? Matthew Ball, a media analyst who has written a lot about Disney+, tells me he suspects it was probably a technical issue more than a content choice.</p>
<p>For <em>Star Wars</em>, though, it's a significant one. <em>Star Wars</em> has a rigidly enforced canon; the movies are its backbone. So having different versions of the movies on people's shelves presents a problem for the hegemony. Like the various translations and apocrypha that Christianity has had to declare, at various moments across millennia, <em>in</em> or <em>out</em>, differing movie versions offer different gospel truths. If Han Solo murdered Greedo, then his decision to return at the climactic moment of <em>A New Hope</em> to help the Rebellion represents an epiphanic change in character. If Han killed Greedo in self-defense, he was always a good person hiding his emotions. (Han manifestly shoots first in the prequel <em>Solo</em>.)</p>
<p>Having multiple iterations of that gunfight—it's like having multiple stories about what happened to Paul on the road to Damascus. Someday, a long time from now, in a castle far, far away, someone is going to have to excavate Drew Stewart's Twitter feed and make some hard decisions about canon and what's apocrypha now.</p>
<p><em>This story originally appeared on <a href="https://www.wired.com/story/star-wars-disney-plus-han-greedo/">wired.com</a>.</em></p>

<p><a href="https://arstechnica.com/?p=1602799&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Google search results have more human help than you think, report finds</title>
		<link>https://arstechnica.com/?p=1602499</link>
		<pubDate>Fri, 15 Nov 2019 21:41:22 +0000</pubDate>
		<dc:creator><![CDATA[Kate Cox]]></dc:creator>
				<category><![CDATA[Policy]]></category>
		<category><![CDATA[antitrust]]></category>
		<category><![CDATA[google]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602499</guid>
		<description><![CDATA[Google is sometimes hands-on under the hood, and investigators want to know more.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/05/getty-googleplex-office-1-800x533.jpg" alt="A large Google sign seen on a window of Google's headquarters."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/05/getty-googleplex-office-1.jpg" class="enlarge-link" data-height="1414" data-width="2121">Enlarge</a> <span class="sep">/</span> Mountain View, Calif.—May 21, 2018: Exterior view of a Googleplex building, the corporate headquarters of Google and parent company Alphabet. (credit: <a rel="nofollow" class="caption-link" href="https://www.gettyimages.com/">Getty Images | zphotos</a>)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Google, and its parent company Alphabet, has its metaphorical fingers in a hundred different lucrative pies. To untold millions of users, though, "to Google" something has become a synonym for "search," the company's original business—a business that is now under investigation as more details about its inner workings come to light.</p>
<p>A coalition of attorneys general investigating Google's practices is expanding its probe to include the company's search business, <a href="https://www.cnbc.com/2019/11/14/states-google-antitrust-probe-to-expand-into-search-android-businesses.html">CNBC reports</a> while citing people familiar with the matter.</p>
<p>Attorneys general for almost every state <a href="https://arstechnica.com/tech-policy/2019/09/50-states-and-territories-launch-massive-joint-probe-into-google/">teamed up</a> in September to launch a joint antitrust probe into Google. The investigation is being led by Texas Attorney General Ken Paxton, who said last month that the probe would first focus on the company's <a href="https://www.bloomberg.com/news/articles/2019-09-10/google-hit-with-sweeping-demand-from-states-over-its-ad-business">advertising business</a>, which continues to dominate the online advertising sector. </p>
<p>Paxton said at the time, however, that he'd willingly take the investigation in new directions if circumstances called for it, telling the <a href="https://www.washingtonpost.com/technology/2019/10/08/texas-attorney-general-googles-new-competition-cop-says-everything-is-table/">Washington Post</a>, "If we end up learning things that lead us in other directions, we’ll certainly bring those back to the states and talk about whether we expand into other areas."</p>
<h2>Why search?</h2>
<p>Google's decades-long dominance in the search market may not be quite as organic as the company has alluded, according to The Wall Street Journal, which <a href="https://www.wsj.com/articles/how-google-interferes-with-its-search-algorithms-and-changes-your-results-11573823753">published a lengthy report</a> today delving into the way Google's black-box search process actually works.</p>
<p>Google's increasingly hands-on approach to search results, which has taken a sharp upturn since 2016, "marks a shift from its founding philosophy of 'organizing the world's information' to one that is far more active in deciding how that information should appear," the WSJ writes.</p>
<p>Some of that manipulation comes from very human hands, sources told the paper in more than 100 interviews. Employees and contractors have "evaluated" search results for effectiveness and quality, among other factors, and promoted certain results to the top of the virtual heap as a result.</p>
<p>One former contractor the WSJ spoke with described down-voting any search results that read like a "how-to manual" for queries relating to suicide until the National Suicide Prevention Lifeline came up as the top result. According to the contractor, Google soon after put out a message to the contracting firm that the Lifeline should be marked as the top result for all searches relating to suicide so that the company algorithms would adjust to consider it the top result.</p>
<p>Or in another instance, sources told the WSJ, employees made a conscious choice for how to handle anti-vax messaging:</p>
<blockquote><p>One of the first hot-button issues surfaced in 2015, according to people familiar with the matter, when some employees complained that a search for “how do vaccines cause autism” delivered misinformation through sites that oppose vaccinations.</p>
<p>At least one employee defended the result, writing that Google should “let the algorithms decide” what shows up, according to one person familiar with the matter. Instead, the people said, Google made a change so that the first result is a site called howdovaccinescauseautism.com—which states on its home page in large black letters, “They f—ing don’t.” (The phrase has become a meme within Google.)</p></blockquote>
<p>The algorithms governing Google's auto-complete and suggestion functions are also heavily subject to review, the sources said. Google says publicly it doesn't allow for predictions related to "harassment, bullying, threats, inappropriate sexualization, or predictions that expose private or sensitive information," and that policy's not new. The engineer who created the auto-complete function in 2004 gave an example using Britney Spears, who at the time was making more headlines for her marriages than for her music.</p>
<p>The engineer "didn't want a piece of human anatomy or the description of a sex act to appear when someone started typing the singer's name," as the paper describes it. The unfiltered search results were "kind of horrible," he added.</p>
<p>The company has since maintained an internal blacklist of terms that are not allowed to appear in autocomplete, organic search, or Google News, the sources told the WSJ, even though company leadership has said publicly, including to Congress, that the company does not use blacklists or whitelists to influence its results.</p>
<p>The modern blacklist reportedly includes not only spam sites, which get de-indexed from search, but also the type of misinformation sites that are endemic to Facebook (or, for that matter, Google's own <a href="https://arstechnica.com/tech-policy/2019/08/youtube-facebook-twitter-nix-fake-anti-hong-kong-propaganda-accounts/">YouTube</a>).</p>
<h2>Why antitrust?</h2>
<p>Google relying on human intervention, and endless tweaks to its algorithms as the WSJ describes, isn't an antitrust violation. When it uses its trove of data from one operation to make choices that may harm competitors to its other operations, though, that can draw attention.</p>
<p>All that human intervention and algorithmic tweaking also affects advertising and business results, according to the WSJ. Those tweaks "favor big businesses over smaller ones," the paper writes, "contrary to [Google's] public position that it never takes that type of action."</p>
<p>The largest advertisers, including eBay, have received "direct advice" on how to improve their search results after seeing traffic from organic search drop, sources told the paper. Smaller businesses, however, have not been so lucky, being left instead to try to figure out the systems either bringing them traffic or denying them traffic on their own.</p>
<p>Links to Google's own features and properties also take up an increasingly large percentage of the search results page, the WSJ notes. For example, if you search for one of today's chart-toppers, such as Beyoncé, you're greeted with three large Google modules that take up more than half the screen real estate:</p>
<div class="image shortcode-img center large"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/beyonce_search.jpg"><img alt='Most of the results on the page are Google modules (highlighted in red).'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/beyonce_search-640x593.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/beyonce_search.jpg 2x" alt='Most of the results on the page are Google modules (highlighted in red).' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/beyonce_search.jpg"class="caption-link" rel="nofollow">Most of the results on the page are Google modules (highlighted in red).</a> </p></div>
<p>More than half of Google searches are now reportedly "no-click" searches, where individuals look only at the page of results and use the snippets on it rather than clicking through to any of the sources from which Google is drawing that information. That kind of use of data, among others, could be considered harmful to competition, since the company is using data collected from competitors to keep users from going to those competitors.</p>
<p>Google, for its part, disputed the WSJ's findings throughout, telling the paper, "We do today what we have done all along, provide relevant results from the most reliable sources available."</p>

<p><a href="https://arstechnica.com/?p=1602499&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Supreme Court agrees to review disastrous ruling on API copyrights</title>
		<link>https://arstechnica.com/?p=1602703</link>
		<pubDate>Fri, 15 Nov 2019 20:57:12 +0000</pubDate>
		<dc:creator><![CDATA[Timothy B. Lee]]></dc:creator>
				<category><![CDATA[Policy]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602703</guid>
		<description><![CDATA[A 2018 ruling on API copyrights could cause problems for the software industry.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2018/03/GettyImages-515609014-800x533.jpg" alt="Signage stands at the Oracle Corp. headquarters campus in Redwood City, California, on March 14, 2016."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2018/03/GettyImages-515609014.jpg" class="enlarge-link" data-height="2333" data-width="3500">Enlarge</a> <span class="sep">/</span> Signage stands at the Oracle Corp. headquarters campus in Redwood City, California, on March 14, 2016. (credit: <a rel="nofollow" class="caption-link" href="https://www.gettyimages.com/collections/bloomberg">Michael Short/Bloomberg via Getty Images</a>)</p>  </figure>






<div><a name='page-1'></a></div>
<p>The Supreme Court has <a href="https://www.supremecourt.gov/orders/courtorders/111519zr_8n59.pdf">agreed to review</a> one of the decade's most significant software copyright decisions: last year's <a href="https://arstechnica.com/tech-policy/2018/03/googles-use-of-the-java-api-packages-was-not-fair-appeals-court-rules/">ruling</a> by an appeals court that Google infringed Oracle's copyrights when Google created an independent implementation of the Java programming language.</p>
<p>The 2018 ruling by the Federal Circuit appeals court "will upend the longstanding expectation of software developers that they are free to use existing software interfaces to build new computer programs," Google wrote in its <a href="http://services.google.com/fh/files/blogs/googlepetition.pdf">January petition</a> to the Supreme Court.</p>
<p>The stakes are high both for Google and for the larger software industry. Until recently, it was widely assumed that copyright law didn't control the use of application programming interfaces (APIs)—standard function calls that allow third parties to build software compatible with an established platform like Java.</p>
<p>But the legal foundation of this assumption was always a bit shaky. And in 2014, the Federal Circuit Appeals Court <a href="https://arstechnica.com/tech-policy/2014/05/oracles-java-api-code-protected-by-copyright-appeals-court-rules/">blew it up</a> with a ruling holding that software APIs actually can be copyrighted. A few years later, the same court <a href="https://arstechnica.com/tech-policy/2018/03/googles-use-of-the-java-api-packages-was-not-fair-appeals-court-rules/">held</a> that Google's use of the Java APIs was not protected by copyright's fair use doctrine.</p>
<p>"The Federal Circuit's decision threatens the continued vitality of software innovation," copyright scholar James Grimmelmann <a href="https://arstechnica.com/tech-policy/2019/01/google-asks-supreme-court-to-overrule-disastrous-ruling-on-api-copyrights/">told me</a> earlier this year. He pointed out that allowing copyright protection for APIs could empower a new generation of copyright trolls that acquire the rights to old software and then sue people building newer software on top of what they thought were open standards. It could also force companies to make software that's deliberately incompatible with its rivals' products, merely to avoid getting hit with a lawsuit.</p>
<h2>Why the case matters</h2>
<p>The Supreme Court agrees to review only a small fraction of lower court decisions. As it often does for cases involving important policy questions, the high court asked the Trump administration to weigh in on whether the case merited Supreme Court attention. The government <a href="https://www.supremecourt.gov/DocketPDF/18/18-956/117359/20190927165110897_18-956%20Google.pdf">said no</a>, arguing that the Federal Circuit Appeals Court had reached the right result when it held that software interfaces could be copyrighted.</p>
<p>But others disagreed. A number of legal scholars, public interest groups, and software companies weighed in on the case, with many arguing that the Federal Circuit's ruling would be detrimental to the software industry. Microsoft, for example, <a href="https://www.supremecourt.gov/DocketPDF/18/18-956/89566/20190225161900311_Brief%20of%20Microsoft%20Corporation%20as%20Amicus%20Curiae.pdf">argued</a> that the ruling "threatens the viability of the interconnected software ecosystem."</p>
<p>A group of legal scholars <a href="https://www.supremecourt.gov/DocketPDF/18/18-956/89474/20190225131314910_IP%20Scholars%20Amicus%20Brief.pdf">pointed out</a> that different appeals courts have reached conflicting opinions about the legal status of APIs. This situation, known as a "circuit split," creates uncertainty about how the law will be applied in the future. The legal scholars urged the high court to take the case so it could establish a uniform legal standard nationwide.</p>
<p>The Supreme Court seems to have found these arguments persuasive.</p>
<p>The Federal Circuit Appeals Court that produced the <em>Google v. Oracle</em> ruling has become something of a whipping boy for the Supreme Court in recent years. The court has exclusive jurisdiction over patent cases nationwide, and it has used that power to make the law significantly more patent-friendly. Over the last 13 years, the Supreme Court has tried to inject some common sense back into patent law by <a href="https://arstechnica.com/tech-policy/2014/06/supreme-court-smashes-do-it-on-a-computer-patents-in-9-0-opinion/">repeatedly</a> <a href="https://arstechnica.com/tech-policy/2012/03/supreme-court-saves-medical-profession-from-diagnostic-patents/">overturning</a> patent-friendly decisions by the Federal Circuit.</p>
<p>Oracle's fight with Google focuses on copyright law, not patents. But because the case initially included some patent issues, the Federal Circuit wound up in charge of the entire case. And the nation's most pro-patent appeals court turns out to favor expansive interpretations of copyright law, too.</p>
<p>The Supreme Court hasn't yet announced when it will hear Google's challenge to Oracle's victory, but it's likely to occur sometime in the new year, with a ruling before the current court session wraps up at the end of June. We'll cover the case every step of the way.</p>

<p><a href="https://arstechnica.com/?p=1602703&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Physicists capture first footage of quantum knots unraveling in superfluid</title>
		<link>https://arstechnica.com/?p=1602547</link>
		<pubDate>Fri, 15 Nov 2019 20:10:41 +0000</pubDate>
		<dc:creator><![CDATA[Jennifer Ouellette]]></dc:creator>
				<category><![CDATA[Science]]></category>
		<category><![CDATA[Physics]]></category>
		<category><![CDATA[quantum knots]]></category>
		<category><![CDATA[quantum physics]]></category>
		<category><![CDATA[science]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602547</guid>
		<description><![CDATA[Research has implications for future topological quantum computers.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knot1-800x420.jpg" alt="Researchers captured the decay of a quantum knot (left), which untied itself after a few microseconds and eventually turned into a spin vortex (right)."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knot1.jpg" class="enlarge-link" data-height="630" data-width="1200">Enlarge</a> <span class="sep">/</span> Researchers captured the decay of a quantum knot (left), which untied itself after a few microseconds and eventually turned into a spin vortex (right). (credit: Tuomas Ollikainen/Aalto University)</p>  </figure>






<div><a name='page-1'></a></div>
<p>The same team who tied the first "quantum knots" in a superfluid several years ago have now discovered that the knots decay, or "untie" themselves, fairly soon after forming, before turning into a vortex. The researchers also produced the first "movie" of the decay process in action, and they described their work in <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.163003">a recent paper</a> in Physical Review Letters.</p>
<p>A mathematician likely would define a true knot as a kind of pretzel shape, or a knotted circle. A quantum knot is a little bit different. It's composed of particle-like rings or loops that connect to each other exactly once. A quantum knot is topologically stable, akin to a soliton—that is, it's a quantum object that acts like a traveling wave that keeps rolling forward at a constant speed without losing its shape.</p>
<p>Physicists had long thought it should be possible for such knotted structures to form in quantum fields, but it proved challenging to produce them in the laboratory. So there was considerable excitement early in 2016 when researchers at Aalto University in Finland and Amherst College in the US announced they had <a href="http://dx.doi.org/10.1038/nphys3624">accomplished the feat</a> in Nature Physics. The knots created by Aalto's Mikko Möttönen and Amherst's David Hall resembled smoke rings.</p>
<div class="image shortcode-img center large"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knotB.jpg"><img alt='Quantum knots in a superfluid resemble smoke rings. '  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knotB-640x180.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knotB.jpg 2x" alt='Quantum knots in a superfluid resemble smoke rings. ' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knotB.jpg"class="caption-link" rel="nofollow">Quantum knots in a superfluid resemble smoke rings. </a> (credit: David Hall, Amherst College)</p></div>
<p>Hall and Möttönen used a quantum state of matter known as a Bose-Einstein Condensate (BEC) as their medium—technically a superfluid. Then they "tied" the knots by manipulating magnetic fields. If you think of the quantum field as points in space that each have an orientation—like arrows all pointing up, for instance—the core of a quantum knot would be a circle where the arrows all point down, similar to a <a href="https://www.wikihow.com/Make-an-Eye-of-God">god's eye yarn pattern</a>. “If you followed the magnetic field line, it would go toward the center, but at the last minute it would peel away into a perpendicular direction,” <a href="https://gizmodo.com/physicists-successfully-tie-the-very-first-quantum-knot-1753018637">Hall told Gizmodo</a> in 2016. “It’s a particular way of rotating these arrows that gives you this linked configuration.”</p>
<p>Eventually they got so good at making quantum knots that they were able to make little movies of the exotic structures. Yet it was still not clear what would happen to the quantum knots over time. Sure, they were topologically stable. But Hall and Möttönen thought the knots should shrink over time as a means of minimizing their energy, the same way a bubble naturally assumes a spherical shape, or a ball "wants" to roll down a hill, thereby minimizing its potential energy. In other words, quantum knots might not be dynamically stable, winking out of existence before their superfluid medium decays. If they can outlast their superfluid medium, they would be effectively stable.</p>
<p>The group has since gained even better control over the BEC medium, enabling them to detect the decay of the knots and the formation of a new type of topological defect (a vortex). After creating a knot via a carefully structured magnetic field, they "perturbed" the BEC by removing the field and imaging what happened next. The experiment showed <a href="https://physics.aps.org/synopsis-for/10.1103/PhysRevLett.123.163003">two distinct stages</a> of the decay process. At first, the knot remained stable, while several "ferromagnetic islands" developed in the (nonmagnetic) BEC. But then the knot dissolved after a few hundred milliseconds, and the ferromagnetic islands migrated to the edges of the BEC, leaving a nonmagnetic core at the center. Finally, a vortex of atomic spins formed between the two magnetic regions of the BEC.</p>
<div class="image shortcode-img center large"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knot2.jpg"><img alt='The experimental set-up at Amherst College where quantum gases are made.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knot2-640x438.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knot2.jpg 2x" alt='The experimental set-up at Amherst College where quantum gases are made.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/knot2.jpg"class="caption-link" rel="nofollow">The experimental set-up at Amherst College where quantum gases are made.</a> (credit: David Hall/Amherst College)</p></div>
<p>"The fact that the knot decays is surprising, since topological structures like quantum knots are typically exceptionally stable," <a href="https://www.aalto.fi/en/news/researchers-watch-quantum-knots-untie">said co-author Tuomas Ollikainen</a>. "It’s also exciting for the field because our observation that a three-dimensional quantum defect decays into a one-dimensional defect hasn’t been seen before in these quantum gas systems."</p>
<p>For now, at least, quantum knots remain a laboratory curiosity, but the research might have bearing on ongoing research into building topological quantum computers. Such a device would braid qubits in different topologically stable structures, making the computer more robust against errors. This latest finding indicates that time may be an important factor, given the knots' rate of decay.</p>
<p>"It would be great to see this technology being used some day in a practical application, which may well happen," <a href="https://www.aalto.fi/en/news/researchers-watch-quantum-knots-untie">said Möttönen</a>. "Our latest results show that while quantum knots in atomic gases are exciting, you need to be quick to use them before they untie themselves. Thus the first applications are likely to be found in other systems."</p>
<p>DOI: <em>Physical Review Letters</em>, 2019. <a href="http://dx.doi.org/10.1103/PhysRevLett.123.163003">10.1103/PhysRevLett.123.163003</a>  (<a href="http://arstechnica.com/science/news/2010/03/dois-and-their-discontents-1.ars">About DOIs</a>).</p>

<p><a href="https://arstechnica.com/?p=1602547&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Apple bans vaping apps from the iOS App Store</title>
		<link>https://arstechnica.com/?p=1602621</link>
		<pubDate>Fri, 15 Nov 2019 20:00:10 +0000</pubDate>
		<dc:creator><![CDATA[Timothy B. Lee]]></dc:creator>
				<category><![CDATA[Science]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[App Store]]></category>
		<category><![CDATA[apple]]></category>
		<category><![CDATA[iOS]]></category>
		<category><![CDATA[juul]]></category>
		<category><![CDATA[vaping]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602621</guid>
		<description><![CDATA[Customers can continue using apps they've already downloaded.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-548301123-800x534.jpg" alt="Woman smoking electronic cigarette."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-548301123.jpg" class="enlarge-link" data-height="2578" data-width="3863">Enlarge</a> <span class="sep">/</span> Woman smoking electronic cigarette. (credit: BSIP/UIG/Getty)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Apple has <a href="https://www.axios.com/exclusive-apple-to-remove-vaping-apps-from-store-8669fd94-e92a-4ce4-a9e2-ce5afa598b67.html">removed all 181 vaping-related apps</a> from the iOS App Store, Axios reported on Friday morning. The move follows rising concern about the possible health impacts of vaping.</p>
<p>Some of the banned apps provided news and information about vaping. Some were vaping-themed games. There were also apps that allowed users to adjust the temperature and other settings on their vaping devices.</p>
<p>To avoid breaking functionality for existing customers, Apple is allowing them to continue using vaping apps already on their devices—and to transfer them to new devices. But new users won't be able to download these apps, and new vaping apps can't be published on Apple's store.</p>

<p>Since their inception, e-cigarettes have faced questions about their safety. Manufacturers have portrayed them as a safer alternative to cigarettes, but critics—including <a href="https://arstechnica.com/science/2019/09/juul-gave-presentations-in-schools-to-kids-and-the-fda-is-fuming/">the Food and Drug Administration</a>—say companies haven't proven these claims scientifically. The technology is so new that the long-term health impacts aren't yet clear.</p>
<p>Critics are particularly worried about rising teen vaping. While conventional teen smoking has been on the decline for decades, those gains have been largely offset by a <a href="https://arstechnica.com/science/2019/09/teen-vaping-surge-25-of-12th-graders-report-recent-use-11-daily-use/">rise in e-cigarette use</a> among high school students. The Food and Drug Administration is planning to <a href="https://arstechnica.com/science/2019/10/juul-halts-sales-of-some-flavors-but-not-the-ones-teens-use-most/">ban flavored vaping products</a> to reduce their appeal to children.</p>
<p>In recent months, health officials have confronted a more urgent problem: hundreds of people have <a href="https://arstechnica.com/science/2019/08/vaping-illness-investigations-turn-to-contaminants-counterfeits-report/">fallen ill</a> after using vaping devices. Officials have linked most of the illnesses to off-brand vaping liquids—especially those involving THC, the main active ingredient in marijuana. One possible culprit: a form of vitamin E, common in skin creams, that may become harmful to the lungs if vaporized. This form of vitamin E has been found in some vaping liquids.</p>
<p>So far, these acute health problems seem to afflict a small minority of vaping users who use vaping liquids from unofficial sources. Consumers who stick to mainstream vaping products do not seem to have been affected.</p>

<p><a href="https://arstechnica.com/?p=1602621&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>Huawei finally ships the foldable Mate X, complete with a protective pouch</title>
		<link>https://arstechnica.com/?p=1602535</link>
		<pubDate>Fri, 15 Nov 2019 19:40:01 +0000</pubDate>
		<dc:creator><![CDATA[Ron Amadeo]]></dc:creator>
				<category><![CDATA[Tech]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602535</guid>
		<description><![CDATA[For now it's only in China, but the market's second major foldable is finally out. ]]></description>
				<content:encoded><![CDATA[





<div><a name='page-1'></a></div>
      <ul class="gallery shortcode-gallery gallery-wide">
          <li>
        <div class="gallery-item-content">  
        <div class="gallery-image"><img src="https://cdn.arstechnica.net/wp-content/uploads/2019/02/1-3-980x425.jpg" alt=""></div>
        <p>
          The Huawei Mate X uses one big wraparound display made by BOE.                       [credit:
                        Huawei                        ]
                  </p>
        </div>
      </li>
      </ul>
  

<p>Huawei's futuristic foldable smartphone, the Huawei Mate X, is finally a real product. The phone went on sale in China today for the heart-stopping price of $2,421 (16,999 yuan).</p>
<p>Just like that other foldable smartphone on the market, the Galaxy Fold, the Mate X had a very bumpy road on its way to market full of delays and setbacks. The phone was originally scheduled for release in "the middle of the year," but in the midst of the US' <a href="https://arstechnica.com/tech-policy/2019/05/trump-tries-to-shut-huawei-out-of-us-market-with-executive-order/">Huawei export ban</a> and the Galaxy Fold's <a href="https://arstechnica.com/gadgets/2019/04/after-the-galaxy-fold-breaks-in-the-hands-of-reviewers-samsung-delays-launch/">initial delay</a>, Huawei opted to<a href="https://arstechnica.com/gadgets/2019/06/huawei-like-samsung-delays-its-foldable-smartphone/"> delay the Mate X</a>. The new launch target was September, but when September rolled around, the phone was <a href="https://arstechnica.com/gadgets/2019/08/huaweis-2600-foldable-smartphone-delayed-again/">delayed again</a> to today's November 15 launch date.</p>
<p><aside class="related-stories right">
  <h2 class="subheading notched">Trade War! USA v. China</h2>
	<ul>
	    <li><a class="recommendation-series" href="https://arstechnica.com/tech-policy/2019/10/fcc-will-ban-huawei-and-zte-equipment-in-us-funded-telecom-projects/">FCC plans Huawei/ZTE ban, may require ripping out existing network gear</a></li>
      <li><a class="recommendation-series" href="https://arstechnica.com/tech-policy/2019/10/congress-concerned-teenagers-favorite-app-is-national-security-threat/">Congress concerned teenagers’ favorite app is national security threat</a></li>
      <li><a class="recommendation-series" href="https://arstechnica.com/gadgets/2019/10/the-internets-horrifying-new-method-for-installing-google-apps-on-huawei-phones/">The Internet’s horrifying new method for installing Google apps on Huawei phones</a></li>
      <li><a class="recommendation-series" href="https://arstechnica.com/gadgets/2019/09/huaweis-new-flagship-smartphone-ships-without-google-apps/">Huawei’s new flagship smartphone ships without Google apps</a></li>
      <li><a class="recommendation-series" href="https://arstechnica.com/gadgets/2019/08/report-us-expected-to-give-huawei-another-90-day-export-license/">Report: United States <em>will</em> give Huawei another 90-day export license</a></li>
    </ul>
  <span class="read-more"><a class="recommendation-series" href="https://arstechnica.com/series/us-versus-china/">View more stories</a></span>
</aside>
Not much has changed since the initial announcement. Wrapped around the body of the Mate X is a flexible OLED display made by BOE. The panel is an 8-inch 2480×2200 tablet when open. When closed, it splits into a 2480×1148, 6.6-inch display on the front and a 6.3-inch, 2480×892 display on the back. The back is a bit smaller because it also houses the component bar, which is the one section of the phone that doesn't split in half. This thicker section houses important components like the three cameras, a power button, a fingerprint reader, and a USB-C port on the bottom.</p>
<p>The internals are a Huawei Kirin 980 SoC, 8GB of RAM, 512GB of storage, and a huge 4500mAh battery. 5G support is mandatory in this phone, thanks to the "Balong 5000" modem included in all models. Keep in mind this is only for China's (and the rest of the world's) "mid-band" 5G, not the US' "mmWave" 5G. They are two totally different technologies on different chunks of the spectrum.</p>
<p>The Huawei Mate X is a unique design even within the emerging foldables market so far. Unlike the Galaxy Fold, which puts the foldable display on the inside of the device and opens up like a book, the Mate X wraps the display around the outside of the device. The Mate X design has a few advantages: it can be a phone when folded up and a tablet when unfolded, and it does this all with a single screen, unlike the two screens (inside and outside) that are on the Galaxy Fold. By wrapping the display around the outside of the phone body, the Mate X doesn't put a hard crease in the display, like the Galaxy Fold does. A single camera can act as both the "front" selfie camera and "rear" main camera, just by flipping the phone around.</p>
<p>The major downside to this design is that, for now, the only flexible display cover on the market is a delicate soft plastic. The plastic display covers are easy to scratch, dent, and permanently damage. The Galaxy Fold protects the soft display by putting it on the inside of the phone, so when it's closed, it's not exposed to the world. With the display on the outside, the soft, delicate plastic is going to be constantly grinding against whatever's on the table, or whatever's in your pocket, so the durability of the Mate X is a serious concern. Huawei seems to have a solution, though.</p>
<div class="image shortcode-img center"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/16-1.jpg"><img alt='The Mate X&#039;s protective case.'  src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/16-1-980x683.jpg" alt='The Mate X&#039;s protective case.' ></a><p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/16-1.jpg"class="caption-link" rel="nofollow">The Mate X's protective case.</a> (credit: Huawei)</p></div>
<p>This a protective leather handbag that seems to ship with the phone. It's an envelope style design, and you can't use the phone at all when it's in the case. It's unclear when exactly you're expected to use this. Taking the phone in and out of the case every time you use it would be incredibly cumbersome. Does it come with a belt loop like an old-school Blackberry? Many people use protective cases on their smartphones like a rubber bumper, which allows you to use the phone while having a protective ring of rubber along the outside. It's hard to imagine a case in that style that would protect the Mate X design while it's in use.</p>
<p>Someday, it sounds like we're going to have flexible glass for these foldable devices, and then a design like this will be a lot more feasible. Corning is working on a <a href="https://www.cnet.com/news/corning-bendable-glass-could-come-to-your-foldable-phone-exclusive/">foldable version</a> of Gorilla Glass, and Samsung has <a href="http://english.etnews.com/20191112200001">teamed up</a> with a fellow Korean company called "Dowoo Insys" to make an "ultra-thin glass" that will be used in future Samsung foldables. For now, however, we only have scratchable plastic, and the Mate X seems ahead of its time.</p>
<p>It's not clear if the Mate X will ever leave China. Any foldable at this point is going to be a very expensive, borderline experimentation device with limited appeal. For Huawei specifically, it is still dealing with the fallout from the US export ban. The last phone it launched in Europe, the Mate 30 Pro, <a href="https://arstechnica.com/gadgets/2019/09/huaweis-new-flagship-smartphone-ships-without-google-apps/">didn't come</a> with Google apps.</p>

<p><a href="https://arstechnica.com/?p=1602535&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
		<item>
		<title>“Dirty trickster” Roger Stone convicted on all counts in Mueller indictment</title>
		<link>https://arstechnica.com/?p=1602575</link>
		<pubDate>Fri, 15 Nov 2019 19:00:07 +0000</pubDate>
		<dc:creator><![CDATA[Sean Gallagher]]></dc:creator>
				<category><![CDATA[Biz & IT]]></category>
		<category><![CDATA[Policy]]></category>
		<category><![CDATA[robert mueller]]></category>
		<category><![CDATA[Roger Stone]]></category>
		<category><![CDATA[Russian election interference]]></category>
		<category><![CDATA[WikiLeaks]]></category>

		<guid isPermaLink="false">https://arstechnica.com/?p=1602575</guid>
		<description><![CDATA[Former Trump campaign adviser found guilty of witness intimidation, lies, and obstruction.]]></description>
				<content:encoded><![CDATA[
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-1187864699-800x537.jpg" alt="WASHINGTON, DC - NOVEMBER 15:  Former adviser to US President Donald Trump, Roger Stone departs the E. Barrett Prettyman United States Courthouse after being found guilty of obstructing a congressional investigation into Russia’s interference in the 2016 election on November 15, 2019 in Washington, DC. Stone faced seven felony charges and was found guilty on all counts."/>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-1187864699.jpg" class="enlarge-link" data-height="687" data-width="1024">Enlarge</a> <span class="sep">/</span> WASHINGTON, DC - NOVEMBER 15:  Former adviser to US President Donald Trump, Roger Stone departs the E. Barrett Prettyman United States Courthouse after being found guilty of obstructing a congressional investigation into Russia’s interference in the 2016 election on November 15, 2019 in Washington, DC. Stone faced seven felony charges and was found guilty on all counts. (credit:  Win McNamee / Getty Images)</p>  </figure>






<div><a name='page-1'></a></div>
<p>Ten months after his arrest by a swarm of FBI agents, former Trump adviser and self-proclaimed "dirty trickster" Roger Stone was found guilty of <a href="https://arstechnica.com/tech-policy/2019/01/whatsapp-wikileaks-and-threats-against-a-dog-the-roger-stone-indictment/">all seven felony counts against him,</a> including obstruction of Congress, five counts of false testimony to Congress, and witness tampering. The conviction is the eighth guilty sentence or plea resulting from grand jury indictments spawned by the investigations into Russian election interference by Special Counsel Robert Mueller.</p>
<p>At the center of the case was Stone's quest in the months leading up to the 2016 presidential election to obtain the emails from WikiLeaks stolen by Russian Main Intelligence Directorate (GRU) operatives from the Democratic National Committee and people within Hillary Clinton's presidential campaign organization. Stone frequently bragged about his connections with WikiLeaks' Julian Assange, and Stone communicated with the Trump campaign about WikiLeaks' plans to release those emails “every chance he got,” said lead federal prosecutor Jonathan Kravis.</p>
<p>Stone was found to have concealed the nature of his communications with WikiLeaks and to have lied to Congress about who acted on his behalf in those contacts. And he attempted to dissuade one of those intermediaries, radio personality Randy Credico, from contradicting his false testimony to Congress, making <em>Godfather II </em>references in his messages to Credico—threatening to take away his therapy dog and to order his lawyers to "rip you to shreds." At one point, Stone allegedly even texted Credico, "Prepare to die [expletive]."</p>
<p>Stone communicated these threats and other details over WhatsApp, which he used as a "secure" phone line and for messaging. Because of his weak understanding of WhatsApp, he believed that using the messaging platform would protect his communications from the eyes of investigators. It didn't, as those who received the messages showed them to investigators. Stone also communicated about his activities heavily through emails, which investigators obtained. Stone then lied to Congress about said activities.</p>
<p>During the trial, deputy chairman of the Trump campaign, Rick Gates, testified regarding a July 2016 phone call between Stone and Trump on the heels of WikiLeaks' release of emails from Clinton campaign officials. Gates said that as soon as he completed the call with Stone, Trump announced that "more information" would be coming—a reference to future WikiLeaks releases. (Trump's written response to questions from the Mueller campaign declared that Trump had no memory of specifics of the 21 phone conversations he had with Stone during the campaign.) Stone had said he never talked about his conversations with his WikiLeaks intermediaries with anyone connected to the Trump campaign.</p>
<p>After his indictment, Stone was banned by Judge Amy Berman Jackson from using social media after he <a href="https://www.washingtontimes.com/news/2019/feb/19/roger-stone-ordered-back-court-posting-crosshairs-/?utm_source=GOOGLE&amp;utm_medium=cpc&amp;utm_id=chacka&amp;utm_campaign=TWT+-+DSA&amp;gclid=EAIaIQobChMI86zmk-rs5QIVGKSzCh3CQAfLEAAYASAAEgJ95_D_BwE">posted a photo of Judge Jackson in crosshairs</a> on his Instagram account. Stone had been banned from Twitter after inflammatory posts in 2017. Stone violated Judge Jackson's order 11 times since February.</p>

<p><a href="https://arstechnica.com/?p=1602575&comments=1">Read Comments</a></p>]]></content:encoded>
			</item>
	</channel>
</rss>